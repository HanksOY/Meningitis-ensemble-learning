{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T03:22:47.000415Z",
     "iopub.status.busy": "2025-12-31T03:22:47.000091Z",
     "iopub.status.idle": "2025-12-31T03:22:47.016263Z",
     "shell.execute_reply": "2025-12-31T03:22:47.015543Z",
     "shell.execute_reply.started": "2025-12-31T03:22:47.000387Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFSm6qSsu7jp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix, roc_curve, confusion_matrix, precision_recall_curve, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total CPU cores (logical): {multiprocessing.cpu_count()}\")\n",
    "print(f\"os.cpu_count(): {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated paths to match the exact filenames in your sidebar\n",
    "meningitis_raw = pd.read_csv('full_encoded_meningitis.csv')\n",
    "nonmeningitis_raw = pd.read_csv('full_encoded_non_meningitis.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T17:10:45.974476Z",
     "iopub.status.busy": "2025-12-30T17:10:45.974223Z",
     "iopub.status.idle": "2025-12-30T17:10:45.989353Z",
     "shell.execute_reply": "2025-12-30T17:10:45.988510Z",
     "shell.execute_reply.started": "2025-12-30T17:10:45.974455Z"
    }
   },
   "outputs": [],
   "source": [
    "meningitis_raw = pd.read_csv('E:/Learning/NEU/Amal Lab/Meningitis paper/full_encoded_meningitis.csv')\n",
    "nonmeningitis_raw = pd.read_csv('E:/Learning/NEU/Amal Lab/Meningitis paper/full_encoded_non_meningitis.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: yellow;\">Elimiate Columns that directly indicate meningits</h2>\n",
    "<p style=\"color: yellow;\">We excluded columns starting with '32' that directly indicate meningitis, since they would entail data leaking</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are meningitis related columns (starting with '32') in Meningitis dataset\n",
    "print(\"Checking for columns starting with '32' in meningitis_raw...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all column names\n",
    "all_columns_men = meningitis_raw.columns.tolist()\n",
    "\n",
    "# Find columns that start with \"32\"\n",
    "columns_starting_32_men = [col for col in all_columns_men if str(col).startswith(('320','321','322'))]\n",
    "\n",
    "print(f\"Total columns in dataset: {len(all_columns_men)}\")\n",
    "print(f\"Columns starting with '32': {len(columns_starting_32_men)}\")\n",
    "print()\n",
    "\n",
    "if columns_starting_32_men:\n",
    "    print(\"Found columns starting with '32':\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sort the columns for better readability\n",
    "    columns_starting_32_sorted_men = sorted(columns_starting_32_men)\n",
    "    \n",
    "    for i, col in enumerate(columns_starting_32_sorted_men, 1):\n",
    "        # Check how many patients have this code\n",
    "        count = meningitis_raw[col].sum() if col in meningitis_raw.columns else 0\n",
    "        percentage = (count / len(meningitis_raw)) * 100 if len(meningitis_raw) > 0 else 0\n",
    "        \n",
    "        # Check positive rate when this code is present\n",
    "        if count > 0:\n",
    "            pos_rate = meningitis_raw[meningitis_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "        else:\n",
    "            pos_rate = 0\n",
    "            \n",
    "        print(f\"{i:2d}. {str(col):<8} - Present in {int(count):4d} patients ({percentage:5.2f}%) - Pos rate: {pos_rate:.3f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Detailed analysis of '32' codes:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Group by length for better understanding\n",
    "    length_groups = {}\n",
    "    for col in columns_starting_32_sorted_men:\n",
    "        length = len(str(col))\n",
    "        if length not in length_groups:\n",
    "            length_groups[length] = []\n",
    "        length_groups[length].append(col)\n",
    "    \n",
    "    for length in sorted(length_groups.keys()):\n",
    "        print(f\"\\nLength {length} codes ({len(length_groups[length])} codes):\")\n",
    "        for col in length_groups[length]:\n",
    "            count = int(meningitis_raw[col].sum())\n",
    "            percentage = (count / len(meningitis_raw)) * 100\n",
    "            if count > 0:\n",
    "                pos_rate = meningitis_raw[meningitis_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - Meningitis rate: {pos_rate:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - No patients with this code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are meningitis related columns (starting with '32') in non-meningitis dataset\n",
    "print(\"Checking for columns starting with '32' in nonmeningitis_raw...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all column names\n",
    "all_columns_nonmen = nonmeningitis_raw.columns.tolist()\n",
    "\n",
    "# Find columns that start with \"32\"\n",
    "columns_starting_32_nonmen = [col for col in all_columns_nonmen if str(col).startswith(('320','321','322'))]\n",
    "\n",
    "print(f\"Total columns in dataset: {len(all_columns_nonmen)}\")\n",
    "print(f\"Columns starting with '32': {len(columns_starting_32_nonmen)}\")\n",
    "print()\n",
    "\n",
    "if columns_starting_32_nonmen:\n",
    "    print(\"Found columns starting with '32':\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sort the columns for better readability\n",
    "    columns_starting_32_sorted_nonmen = sorted(columns_starting_32_nonmen)\n",
    "    \n",
    "    for i, col in enumerate(columns_starting_32_sorted_nonmen, 1):\n",
    "        # Check how many patients have this code\n",
    "        count = nonmeningitis_raw[col].sum() if col in nonmeningitis_raw.columns else 0\n",
    "        percentage = (count / len(nonmeningitis_raw)) * 100 if len(nonmeningitis_raw) > 0 else 0\n",
    "        \n",
    "        # Check positive rate when this code is present\n",
    "        if count > 0:\n",
    "            pos_rate = nonmeningitis_raw[nonmeningitis_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "        else:\n",
    "            pos_rate = 0\n",
    "            \n",
    "        print(f\"{i:2d}. {str(col):<8} - Present in {int(count):4d} patients ({percentage:5.2f}%) - Pos rate: {pos_rate:.3f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Detailed analysis of '32' codes:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Group by length for better understanding\n",
    "    length_groups = {}\n",
    "    for col in columns_starting_32_sorted_nonmen:\n",
    "        length = len(str(col))\n",
    "        if length not in length_groups:\n",
    "            length_groups[length] = []\n",
    "        length_groups[length].append(col)\n",
    "    \n",
    "    for length in sorted(length_groups.keys()):\n",
    "        print(f\"\\nLength {length} codes ({len(length_groups[length])} codes):\")\n",
    "        for col in length_groups[length]:\n",
    "            count = int(nonmeningitis_raw[col].sum())\n",
    "            percentage = (count / len(nonmeningitis_raw)) * 100\n",
    "            if count > 0:\n",
    "                pos_rate = nonmeningitis_raw[nonmeningitis_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - Meningitis rate: {pos_rate:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - No patients with this code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create new dataset without meningitis code columns\n",
    "meningitis_clean = meningitis_raw.drop(columns=columns_starting_32_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns that start with \"('320','321','322')\"\n",
    "all_columns_clean_men = meningitis_clean.columns.tolist()\n",
    "\n",
    "columns_starting_32_clean = [col for col in all_columns_clean_men if str(col).startswith(('320','321','322'))]\n",
    "\n",
    "print(f\"Total columns in dataset: {len(all_columns_clean_men)}\")\n",
    "print(f\"Columns starting with '('320','321','322')': {len(columns_starting_32_clean)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nonmeningitis_raw[\"CLASSIFIER\"] == 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB4PqdHf6eZ_",
    "outputId": "56f0df74-05be-4164-c6e1-1d128b16dca7"
   },
   "outputs": [],
   "source": [
    "print(meningitis_clean.shape)\n",
    "print(nonmeningitis_raw.shape)\n",
    "print(meningitis_clean.head)\n",
    "print(nonmeningitis_raw.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wl06X95qAuy0"
   },
   "outputs": [],
   "source": [
    "# Ramdonly extract 180 samples for training set and 34 samples for testing set in meningitis cohort\n",
    "men_180 = meningitis_clean.sample(n=180, random_state=42)\n",
    "men_34 = meningitis_clean.drop(men_180.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKilv_yLAuy0",
    "outputId": "4f87009a-b2b2-4992-d3c7-64eae940501d"
   },
   "outputs": [],
   "source": [
    "print(men_180.head)\n",
    "print(men_34.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZ46Zql7Auy0"
   },
   "outputs": [],
   "source": [
    "# Ramdonly extract 38955 samples for training set and 7348 samples for testing set in the non-meningitis cohort\n",
    "non_men_38955 = nonmeningitis_raw.sample(n=38955, random_state=42)\n",
    "non_men_7348 = nonmeningitis_raw.drop(non_men_38955.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract samples from non_men_38955 that at least 1 of the top-100 most important features has a value of 1\n",
    "def extract_negatives_with_topk_ones(non_men_38955: pd.DataFrame,\n",
    "                                     top_100_features,\n",
    "                                     k: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep rows where at least k of the top-100 features == 1 (or True).\n",
    "    - negative_samples: DataFrame with 0/1 (or bool) feature columns\n",
    "    - top_100_features: iterable of feature names (list/Index)\n",
    "    - k: threshold count (default 1)\n",
    "    \"\"\"\n",
    "    cols = [c for c in top_100_features if c in non_men_38955.columns]\n",
    "    if not cols:\n",
    "        return non_men_38955.iloc[0:0].copy()\n",
    "\n",
    "    sub = non_men_38955[cols]\n",
    "    # Count how many of the selected features are 1/True in each row\n",
    "    hits = (sub.eq(1) | sub.eq(True)).sum(axis=1)\n",
    "    return non_men_38955.loc[hits >= k].copy()\n",
    "\n",
    "# Example\n",
    "nonmen_1plus = extract_negatives_with_topk_ones(non_men_38955, top_100_features, k=1)\n",
    "print(nonmen_1plus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnURruCgAuy1"
   },
   "outputs": [],
   "source": [
    "# Ramdonly extract 180 and 8000 samples for training set in the non-meningitis cohort\n",
    "non_men_180 = non_men_38955.sample(n=180, random_state=42)\n",
    "\n",
    "# Randonly extract 180*10 = 1800, 180*20 = 3600, 180*30 = 5400 from 38955 non-meningitis samples for model training with Case-control subgroups\n",
    "non_men_1800 = non_men_38955.sample(n=1800, random_state=42)\n",
    "non_men_3600 = non_men_38955.sample(n=3600, random_state=42)\n",
    "non_men_5400 = non_men_38955.sample(n=5400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_men_180_sim = nonmen_1plus.sample(n=180, random_state=42)\n",
    "non_men_1800_sim = nonmen_1plus.sample(n=1800, random_state=42)\n",
    "non_men_3600_sim = nonmen_1plus.sample(n=3600, random_state=42)\n",
    "non_men_5400_sim = nonmen_1plus.sample(n=5400, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5mmXZwIAuy1",
    "outputId": "d679fd0b-8ea2-4681-b4fb-8e2e5b96d604"
   },
   "outputs": [],
   "source": [
    "print(non_men_38955.head)\n",
    "print(non_men_7348.head)\n",
    "print(non_men_180.head)\n",
    "print(non_men_1800.head)\n",
    "print(non_men_3600.head)\n",
    "print(non_men_5400.head)\n",
    "print(non_men_180_sim.head)\n",
    "print(non_men_1800_sim.head)\n",
    "print(non_men_3600_sim.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZ-_clGZAuy1"
   },
   "outputs": [],
   "source": [
    "# Combine data for training set and testing set\n",
    "training_combined = pd.concat([men_180, non_men_38955], ignore_index = True)\n",
    "\n",
    "# Combine data for training set \n",
    "# This is useful for testing purposes or small-scale experiments\n",
    "training_combined_360 = pd.concat([men_180, non_men_180], ignore_index = True)\n",
    "training_combined_1980 = pd.concat([men_180, non_men_1800], ignore_index = True)\n",
    "training_combined_3780 = pd.concat([men_180, non_men_3600], ignore_index = True)\n",
    "training_combined_5580 = pd.concat([men_180, non_men_5400], ignore_index = True)\n",
    "testing_combined_7382 = pd.concat([men_34, non_men_7348], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data for training set of simulation\n",
    "training_combined_360_sim = pd.concat([men_180, non_men_180_sim], ignore_index = True)\n",
    "training_combined_1980_sim = pd.concat([men_180, non_men_1800_sim], ignore_index = True)\n",
    "training_combined_3780_sim = pd.concat([men_180, non_men_3600_sim], ignore_index = True)\n",
    "training_combined_5580_sim = pd.concat([men_180, non_men_5400_sim], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ul3d0eGFAuy1"
   },
   "outputs": [],
   "source": [
    "# Drop SUBJECT_ID of training sets\n",
    "training_ID_Drop = training_combined.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_360 = training_combined_360.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_1980 = training_combined_1980.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_3780 = training_combined_3780.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_5580 = training_combined_5580.drop('SUBJECT_ID', axis = 1)\n",
    "\n",
    "# Drop SUBJECT_ID of testing sets\n",
    "testing_ID_Drop_7382 = testing_combined_7382.drop('SUBJECT_ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ID_Drop_360_sim = training_combined_360_sim.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_1980_sim = training_combined_1980_sim.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_3780_sim = training_combined_3780_sim.drop('SUBJECT_ID', axis = 1)\n",
    "training_ID_Drop_5580_sim = training_combined_5580_sim.drop('SUBJECT_ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUcnjxgZAuy1"
   },
   "outputs": [],
   "source": [
    "# Shuffle the training datasets to ensure random distribution\n",
    "training_shuffled = training_ID_Drop.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_360 = training_ID_Drop_360.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_1980 = training_ID_Drop_1980.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_3780 = training_ID_Drop_3780.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_5580 = training_ID_Drop_5580.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the testing datasets to ensure random distribution\n",
    "testing_shuffled_7382 = testing_ID_Drop_7382.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_shuffled_360_sim = training_ID_Drop_360_sim.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_1980_sim = training_ID_Drop_1980_sim.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_3780_sim = training_ID_Drop_3780_sim.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "training_shuffled_5580_sim = training_ID_Drop_5580_sim.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JxGI9uwMBth",
    "outputId": "63504de2-3b17-49a1-99ea-bc2e8b52428e"
   },
   "outputs": [],
   "source": [
    "print(training_shuffled.shape)\n",
    "print(training_shuffled_360.shape)\n",
    "print(training_shuffled_1980.shape)\n",
    "print(training_shuffled_3780.shape)\n",
    "print(training_shuffled_5580.shape)\n",
    "\n",
    "print(testing_shuffled_7382.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqeN2PZNTWud",
    "outputId": "29b5bb41-46ca-4485-c45b-79646ab3bdbb"
   },
   "outputs": [],
   "source": [
    "# Check for NaN values in each dataset\n",
    "print(\"NaN values in training data:\\n\", training_shuffled.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in training data (360 samples):\\n\", training_shuffled_360.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in training data (1980 samples):\\n\", training_shuffled_1980.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in training data (3780 samples):\\n\", training_shuffled_3780.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in training data (5580 samples):\\n\", training_shuffled_5580.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in testing data with 7382 samples:\\n\", testing_shuffled_7382.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_360_sim = training_shuffled_360_sim.fillna(0)\n",
    "df_training_1980_sim = training_shuffled_1980_sim.fillna(0)\n",
    "df_training_3780_sim = training_shuffled_3780_sim.fillna(0)\n",
    "df_training_5580_sim = training_shuffled_5580_sim.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_360_sim.shape\n",
    "df_training_1980_sim.shape\n",
    "df_training_3780_sim.shape\n",
    "df_training_5580_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hRr6QzJT6ar",
    "outputId": "86b139e9-80b8-4a8d-ebf6-8bf3a62b17f9"
   },
   "outputs": [],
   "source": [
    "# Replace NaN values with 0 in each dataset\n",
    "df_training = training_shuffled.fillna(0)\n",
    "df_training_360 = training_shuffled_360.fillna(0)\n",
    "df_training_1980 = training_shuffled_1980.fillna(0)\n",
    "df_training_3780 = training_shuffled_3780.fillna(0)\n",
    "df_training_5580 = training_shuffled_5580.fillna(0)\n",
    "df_testing_7382 = testing_shuffled_7382.fillna(0)\n",
    "# Verify if NaN values are replaced\n",
    "print(\"NaN values in df_training:\\n\", df_training.isnull().sum())\n",
    "print(\"\\nNaN values in df_testing:\\n\", df_testing_7382.isnull().sum())\n",
    "print(\"\\nNaN values in df_training_1980:\\n\", df_training_1980.isnull().sum())\n",
    "print(\"\\nNaN values in df_training_3780:\\n\", df_training_3780.isnull().sum())\n",
    "print(\"\\nNaN values in df_training_5580:\\n\", df_training_5580.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate column names in training data\n",
    "duplicate_columns = df_training_360.columns[df_training_360.columns.duplicated()].unique()\n",
    "duplicate_columns_1980 = df_training_1980.columns[df_training_1980.columns.duplicated()].unique()\n",
    "duplicate_columns_3780 = df_training_3780.columns[df_training_3780.columns.duplicated()].unique()\n",
    "duplicate_columns_5580 = df_training_5580.columns[df_training_5580.columns.duplicated()].unique()\n",
    "\n",
    "print(duplicate_columns)\n",
    "print(duplicate_columns_1980)\n",
    "print(duplicate_columns_3780)\n",
    "print(duplicate_columns_5580)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Feature Importance Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: yellow;\">Conduct Feature Importance</h2>\n",
    "<p style=\"color: yellow;\">1. Find out features that are most related to meningitis;<br> 2. A simulated situation in ER that includes 50% non-meningitis cases is needed. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df_training.drop('CLASSIFIER', axis=1)\n",
    "y = df_training['CLASSIFIER']\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Positive class ratio: {y.mean():.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest for feature importance\n",
    "print(\"Training Random Forest for feature importance...\")\n",
    "rf_importance = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "rf_importance.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_importance.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_importance_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 100 most important features:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (idx, row) in enumerate(feature_importance_df.head(100).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {row['feature']:8s} : {row['importance']:.6f}\")\n",
    "\n",
    "print(\"/n\" + \"Feature importance distribution:\")\n",
    "print(f\"Max importance: {feature_importance_df['importance'].max():.6f}\")\n",
    "print(f\"Mean importance: {feature_importance_df['importance'].mean():.6f}\")\n",
    "print(f\"Min importance: {feature_importance_df['importance'].min():.6f}\")\n",
    "print(f\"Features with importance > 0.001: {(feature_importance_df['importance'] > 0.001).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 100 features\n",
    "top_100_features = feature_importance_df.head(100)['feature'].tolist()\n",
    "\n",
    "print(\"Top 100 most important features selected:\")\n",
    "print(f\"Feature importance range: {top_100_features[0]} ({feature_importance_df.iloc[0]['importance']:.6f}) to {top_100_features[99]} ({feature_importance_df.iloc[99]['importance']:.6f})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new training dataset with top 50 features + target\n",
    "df_training_important = df_training[top_100_features + ['CLASSIFIER']].copy()\n",
    "\n",
    "print(\"New dataset created: df_training_important\")\n",
    "print(f\"New dataset shape: {df_training_important.shape}\")\n",
    "print(f\"Features reduced from {X.shape[1]} to {len(top_100_features)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the selection worked correctly\n",
    "print(\"Verification:\")\n",
    "print(f\"All features present: {set(top_100_features).issubset(set(df_training_important.columns))}\")\n",
    "print(f\"CLASSIFIER column present: {'CLASSIFIER' in df_training_important.columns}\")\n",
    "print(f\"No missing values in new dataset: {df_training_important.isnull().sum().sum() == 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(range(1, 101), feature_importance_df.head(100)['importance'])\n",
    "plt.title('Top 100 Feature Importances')\n",
    "plt.xlabel('Feature Rank')\n",
    "plt.ylabel('Importance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(feature_importance_df['importance'], bins=50, alpha=0.7)\n",
    "plt.axvline(feature_importance_df.iloc[99]['importance'], color='red', linestyle='--', \n",
    "           label=f'100th feature: {feature_importance_df.iloc[99][\"importance\"]:.6f}')\n",
    "plt.title('Feature Importance Distribution')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(range(1, 21), feature_importance_df.head(20)['importance'])\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.xlabel('Feature Rank')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(range(1, 21, 2))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "cumulative_importance = np.cumsum(feature_importance_df['importance'])\n",
    "plt.plot(range(1, len(cumulative_importance) + 1), cumulative_importance)\n",
    "plt.axvline(100, color='red', linestyle='--', label='Top 100 features')\n",
    "plt.axhline(cumulative_importance[99], color='red', linestyle='--', \n",
    "           label=f'Cumulative: {cumulative_importance[99]:.3f}')\n",
    "plt.title('Cumulative Feature Importance')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_important.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: yellow;\">Handle Testing Dataset</h2>\n",
    "<p style=\"color: yellow;\">The main idea of this section is that the positive samples (\"CLASSIFIER\" == 1) are extracted and combined with negative samples (\"CLASSIFIER\" == 1) in order to test the model performance under the condition of balanced and imbalanced testing datasets. We search samples in negatives where each one has at least 2 similar features extracted from top 100 features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative samples\n",
    "positive_samples = df_testing_7382[df_testing_7382['CLASSIFIER'] == 1]\n",
    "negative_samples = df_testing_7382[df_testing_7382['CLASSIFIER'] == 0]\n",
    "\n",
    "len(positive_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract samples from negative_samples that at least 2 of the top-100 most important features has a value of 1\n",
    "def extract_negatives_with_topk_ones(negative_samples: pd.DataFrame,\n",
    "                                     top_100_features,\n",
    "                                     k: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep rows where at least k of the top-100 features == 1 (or True).\n",
    "    - negative_samples: DataFrame with 0/1 (or bool) feature columns\n",
    "    - top_100_features: iterable of feature names (list/Index)\n",
    "    - k: threshold count (default 1)\n",
    "    \"\"\"\n",
    "    cols = [c for c in top_100_features if c in negative_samples.columns]\n",
    "    if not cols:\n",
    "        return negative_samples.iloc[0:0].copy()\n",
    "\n",
    "    sub = negative_samples[cols]\n",
    "    # Count how many of the selected features are 1/True in each row\n",
    "    hits = (sub.eq(1) | sub.eq(True)).sum(axis=1)\n",
    "    return negative_samples.loc[hits >= k].copy()\n",
    "\n",
    "# Example\n",
    "selected_2plus = extract_negatives_with_topk_ones(negative_samples, top_100_features, k=2)\n",
    "print(selected_2plus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple testing sets\n",
    "df_testing_68 = pd.concat([positive_samples, negative_samples.sample(n=34, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_374 = pd.concat([positive_samples, negative_samples.sample(n=340, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_714 = pd.concat([positive_samples, negative_samples.sample(n=680, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_1054 = pd.concat([positive_samples, negative_samples.sample(n=1020, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_7382 = pd.concat([positive_samples, negative_samples.sample(n=7348, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Simulation testing sets (no df_testing_7382 due to less similation sample size than original size)\n",
    "df_testing_68_sim = pd.concat([positive_samples, selected_2plus.sample(n=34, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_374_sim = pd.concat([positive_samples, selected_2plus.sample(n=340, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_714_sim = pd.concat([positive_samples, selected_2plus.sample(n=680, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_testing_1054_sim = pd.concat([positive_samples, selected_2plus.sample(n=1020, random_state=42)], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_testing_374_sim.shape)\n",
    "print(df_testing_714_sim.shape)\n",
    "print(df_testing_1054_sim.shape)\n",
    "\n",
    "\n",
    "print(df_testing_68.shape)\n",
    "print(df_testing_374.shape)\n",
    "print(df_testing_714.shape)\n",
    "print(df_testing_1054.shape)\n",
    "print(df_testing_7382.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate column names after concatenation\n",
    "duplicate_columns_testing_68 = df_testing_68.columns[df_testing_68.columns.duplicated()].unique()\n",
    "\n",
    "print(df_testing_68.shape)\n",
    "duplicate_columns_testing_68_sim = df_testing_68_sim.columns[df_testing_68_sim.columns.duplicated()].unique()\n",
    "\n",
    "print(f'Number of duplicate_columns_testing_68: {duplicate_columns_testing_68}')\n",
    "print(f'Number of duplicate_columns_testing_68_sim: {duplicate_columns_testing_68_sim}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T03:27:39.744047Z",
     "iopub.status.busy": "2025-12-31T03:27:39.743716Z",
     "iopub.status.idle": "2025-12-31T03:27:39.748055Z",
     "shell.execute_reply": "2025-12-31T03:27:39.747001Z",
     "shell.execute_reply.started": "2025-12-31T03:27:39.744021Z"
    }
   },
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "# Random Forest Training Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: yellow;\">Model Training</h2>\n",
    "<p style=\"color: yellow;\">1. Random Forest, LightGBM and DNN are trained with Cost-sensitive Learning respectively. <br>2. After training, we are able to get based models and \"ouf of fold\" data that are used on \"meta model\" for Ensemble Learning.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF(df, batch_size=64, n_splits=5, n_estimators=500):\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = df.drop('CLASSIFIER', axis=1).values\n",
    "    y = df['CLASSIFIER'].values\n",
    "\n",
    "    # Cross-validation setup\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    metrics = {'AUC': [], 'Sensitivity': [], 'Specificity': [], 'PPV': [], 'NPV': [], 'F1-score': []}\n",
    "\n",
    "    fold_number = 1\n",
    "    fpr_list = []\n",
    "    tpr_list = []\n",
    "\n",
    "    # Placeholder for out-of-fold predictions\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    \n",
    "    # Print the training dataset size\n",
    "    print(f\"Training Random Forest with {X.shape[0]} samples:\")\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        df_name = [name for name, val in globals().items() if val is df][0]\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Convert data to numpy arrays\n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "\n",
    "        n_neg = np.sum(y_train == 0)\n",
    "        n_pos = np.sum(y_train == 1)\n",
    "        # Standard balanced weight\n",
    "        weight_ratio = n_neg / n_pos\n",
    "        # More aggressive: multiply by 2-3x\n",
    "        aggressive_weight_ratio = weight_ratio * 0.8\n",
    "        class_weight_dict = {0: 1.0, 1: aggressive_weight_ratio}\n",
    "\n",
    "        # Define and train Random Forest model\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            class_weight=class_weight_dict  # Keep this\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_probs = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # OPTIMAL THRESHOLD SELECTION - Youden's J statistic\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "        youden_j = tpr - fpr\n",
    "        optimal_idx = np.argmax(youden_j)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        # Alternative: F1-maximizing threshold\n",
    "        # from sklearn.metrics import f1_score\n",
    "        # thresholds_f1 = np.arange(0.1, 0.9, 0.01)\n",
    "        # f1_scores = [f1_score(y_test, (y_pred_probs >= t).astype(int)) for t in thresholds_f1]\n",
    "        # optimal_threshold = thresholds_f1[np.argmax(f1_scores)]\n",
    "        \n",
    "        # Use optimal threshold instead of 0.5\n",
    "        y_pred = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Print threshold info for debugging\n",
    "        if fold_number == 1:\n",
    "            print(f\"  Optimal threshold (fold {fold_number}): {optimal_threshold:.4f}\")\n",
    "            print(f\"  Probability range: [{y_pred_probs.min():.4f}, {y_pred_probs.max():.4f}]\")\n",
    "            print(f\"  Positive predictions with optimal threshold: {y_pred.sum()} / {len(y_pred)}\")\n",
    "\n",
    "        # Save OOF predictions in the correct indices\n",
    "        oof_preds[test_index] = y_pred_probs\n",
    "        \n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(y_test, y_pred_probs)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else np.nan\n",
    "        f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else np.nan\n",
    "\n",
    "        # Append metrics for the fold\n",
    "        metrics['AUC'].append(auc)\n",
    "        metrics['Sensitivity'].append(sensitivity)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "        metrics['PPV'].append(ppv)\n",
    "        metrics['NPV'].append(npv)\n",
    "        metrics['F1-score'].append(f1)\n",
    "\n",
    "        # Collect data for plotting ROC curve\n",
    "        fpr_list.append(fpr)\n",
    "        tpr_list.append(tpr)\n",
    "\n",
    "        fold_number += 1\n",
    "\n",
    "    # Calculate mean and 95% CI for each metric\n",
    "    def compute_mean_ci(values):\n",
    "        mean = np.mean(values)\n",
    "        lower = np.percentile(values, 2.5)\n",
    "        upper = np.percentile(values, 97.5)\n",
    "        return mean, (lower, upper)\n",
    "\n",
    "    for metric, values in metrics.items():\n",
    "        mean, ci = compute_mean_ci(values)\n",
    "        print(f\"{metric}: {mean:.4f} (95% CI: {ci[0]:.4f} - {ci[1]:.4f})\")\n",
    "\n",
    "    # Plot ROC curve for each fold\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(n_splits):\n",
    "        plt.plot(fpr_list[i], tpr_list[i], label=f'Fold {i+1} (AUC = {metrics[\"AUC\"][i]:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f\"ROC Curve of {df_name} using Random Forest\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 1800 samples (in df_training_198) as training set\n",
    "model_RF_1980, oof_preds_RF_1980 = train_RF(df_training_1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 3600 samples (in df_training_3780) as training set\n",
    "model_RF_3780, oof_preds_RF_3780 = train_RF(df_training_3780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 5400 samples (in df_training_5580) as training set\n",
    "model_RF_5580, oof_preds_RF_5580 = train_RF(df_training_5580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 38955 samples (in df_training) as training set\n",
    "model_RF, oof_preds_RF = train_RF(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKDucW5zAuy2",
    "outputId": "bedd224c-1fde-4035-9ce3-a49bd2604de7"
   },
   "outputs": [],
   "source": [
    "model_RF_360, oof_preds_RF_360 = train_RF(df_training_360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LHPd_9UAuy3"
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# LightGBM Training Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LightGBM(df, batch_size=64, n_splits=5, n_estimators=100):\n",
    "    # Separate features and target variable\n",
    "    X = df.drop('CLASSIFIER', axis=1).values\n",
    "    y = df['CLASSIFIER'].values\n",
    "\n",
    "    # Cross-validation setup\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    metrics = {'AUC': [], 'Sensitivity': [], 'Specificity': [], 'PPV': [], 'NPV': [], 'F1-score': []}\n",
    "\n",
    "    fold_number = 1\n",
    "    fpr_list = []\n",
    "    tpr_list = []\n",
    "\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"Training LightGBM with {X.shape[0]} samples:\")\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        df_name = [name for name, val in globals().items() if val is df][0]\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Convert data to numpy arrays\n",
    "        X_train = X_train.astype(np.float32)\n",
    "        X_test = X_test.astype(np.float32)\n",
    "\n",
    "        # Calculate class weights - conservative approach for better PPV and Specificity\n",
    "        n_neg = np.sum(y_train == 0)\n",
    "        n_pos = np.sum(y_train == 1)\n",
    "        \n",
    "        if n_pos > 0:\n",
    "            pos_weight = n_neg / n_pos\n",
    "            # Further reduced multiplier to improve PPV and Specificity\n",
    "            # Lower multiplier reduces false positives\n",
    "            aggressive_pos_weight = pos_weight * 0.75  # Reduced from 0.9\n",
    "        else:\n",
    "            aggressive_pos_weight = 1.0\n",
    "\n",
    "        # Enhanced LightGBM with hyperparameters optimized for PPV and Specificity\n",
    "        model = lgb.LGBMClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=8,  # Further reduced depth to reduce overfitting\n",
    "            num_leaves=40,  # Further reduced leaves\n",
    "            min_child_samples=60,  # Further increased to reduce false positives\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            scale_pos_weight=aggressive_pos_weight,  # Cost-sensitive learning\n",
    "            reg_alpha=0.3,  # Further increased regularization\n",
    "            reg_lambda=0.3,\n",
    "            random_state=42,\n",
    "            verbose=-1,\n",
    "            boost_from_average=False,\n",
    "            objective='binary',\n",
    "            metric='binary_logloss',\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_probs = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # OPTIMIZE THRESHOLD: Prioritize PPV and Specificity\n",
    "        # Use precision-recall curve for better PPV optimization\n",
    "        precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_probs)\n",
    "        \n",
    "        best_score = -1\n",
    "        optimal_threshold = 0.5\n",
    "        best_metrics = {}\n",
    "        \n",
    "        # Target: High PPV (>= 0.25) and High Specificity (>= 0.70) with reasonable sensitivity (>= 0.70)\n",
    "        min_sensitivity = 0.70  # Minimum acceptable sensitivity\n",
    "        min_ppv = 0.25  # Minimum PPV target\n",
    "        min_specificity = 0.70  # Minimum Specificity target\n",
    "        \n",
    "        # Strategy 1: Find threshold that maximizes composite score of PPV and Specificity\n",
    "        for i, threshold in enumerate(thresholds_pr):\n",
    "            y_pred_temp = (y_pred_probs >= threshold).astype(int)\n",
    "            \n",
    "            if np.sum(y_pred_temp) > 0 and np.sum(y_test) > 0:\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test, y_pred_temp).ravel()\n",
    "                sensitivity_temp = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                ppv_temp = precision[i]  # Use precision from PR curve\n",
    "                specificity_temp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                \n",
    "                # Check if minimum sensitivity is met\n",
    "                if sensitivity_temp >= min_sensitivity:\n",
    "                    # Composite score: balance PPV and Specificity (both reduce false positives)\n",
    "                    # Equal weight on PPV and Specificity, with some weight on sensitivity\n",
    "                    composite_score = 0.5 * ppv_temp + 0.4 * specificity_temp + 0.1 * sensitivity_temp\n",
    "                    \n",
    "                    if composite_score > best_score:\n",
    "                        best_score = composite_score\n",
    "                        optimal_threshold = threshold\n",
    "                        best_metrics = {\n",
    "                            'sensitivity': sensitivity_temp,\n",
    "                            'ppv': ppv_temp,\n",
    "                            'specificity': specificity_temp,\n",
    "                            'composite': composite_score,\n",
    "                            'f1': 2 * (ppv_temp * sensitivity_temp) / (ppv_temp + sensitivity_temp + 1e-10)\n",
    "                        }\n",
    "        \n",
    "        # Strategy 2: If no threshold meets all requirements, relax constraints\n",
    "        if best_score == -1:\n",
    "            print(f\"  Warning: No threshold meets all constraints. Relaxing...\")\n",
    "            \n",
    "            # Try with relaxed PPV and Specificity\n",
    "            min_ppv_relaxed = 0.20\n",
    "            min_specificity_relaxed = 0.65\n",
    "            \n",
    "            for i, threshold in enumerate(thresholds_pr):\n",
    "                y_pred_temp = (y_pred_probs >= threshold).astype(int)\n",
    "                \n",
    "                if np.sum(y_pred_temp) > 0 and np.sum(y_test) > 0:\n",
    "                    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_temp).ravel()\n",
    "                    sensitivity_temp = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                    ppv_temp = precision[i]\n",
    "                    specificity_temp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                    \n",
    "                    if (sensitivity_temp >= min_sensitivity and \n",
    "                        ppv_temp >= min_ppv_relaxed and \n",
    "                        specificity_temp >= min_specificity_relaxed):\n",
    "                        composite_score = 0.5 * ppv_temp + 0.4 * specificity_temp + 0.1 * sensitivity_temp\n",
    "                        if composite_score > best_score:\n",
    "                            best_score = composite_score\n",
    "                            optimal_threshold = threshold\n",
    "                            best_metrics = {\n",
    "                                'sensitivity': sensitivity_temp,\n",
    "                                'ppv': ppv_temp,\n",
    "                                'specificity': specificity_temp,\n",
    "                                'composite': composite_score,\n",
    "                                'f1': 2 * (ppv_temp * sensitivity_temp) / (ppv_temp + sensitivity_temp + 1e-10)\n",
    "                            }\n",
    "        \n",
    "        # Strategy 3: If still no threshold, use grid search with PPV+Specificity optimization\n",
    "        if best_score == -1:\n",
    "            thresholds_grid = np.arange(0.3, 0.95, 0.01)\n",
    "            \n",
    "            for threshold in thresholds_grid:\n",
    "                y_pred_temp = (y_pred_probs >= threshold).astype(int)\n",
    "                if np.sum(y_pred_temp) > 0:\n",
    "                    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_temp).ravel()\n",
    "                    sensitivity_temp = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                    ppv_temp = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                    specificity_temp = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                    \n",
    "                    if sensitivity_temp >= 0.65:  # Minimum sensitivity\n",
    "                        # Optimize for PPV and Specificity\n",
    "                        composite_score = 0.5 * ppv_temp + 0.4 * specificity_temp + 0.1 * sensitivity_temp\n",
    "                        if composite_score > best_score:\n",
    "                            best_score = composite_score\n",
    "                            optimal_threshold = threshold\n",
    "                            best_metrics = {\n",
    "                                'sensitivity': sensitivity_temp,\n",
    "                                'ppv': ppv_temp,\n",
    "                                'specificity': specificity_temp,\n",
    "                                'composite': composite_score,\n",
    "                                'f1': 2 * (ppv_temp * sensitivity_temp) / (ppv_temp + sensitivity_temp + 1e-10)\n",
    "                            }\n",
    "        \n",
    "        # Use optimal threshold\n",
    "        y_pred = (y_pred_probs >= optimal_threshold).astype(int)\n",
    "        \n",
    "        # Debug info for first fold\n",
    "        if fold_number == 1:\n",
    "            print(f\"  Optimal threshold (fold {fold_number}): {optimal_threshold:.4f}\")\n",
    "            print(f\"  Best composite score: {best_metrics.get('composite', 0):.4f}\")\n",
    "            print(f\"  Sensitivity: {best_metrics.get('sensitivity', 0):.4f}, PPV: {best_metrics.get('ppv', 0):.4f}\")\n",
    "            print(f\"  Specificity: {best_metrics.get('specificity', 0):.4f}, F1: {best_metrics.get('f1', 0):.4f}\")\n",
    "            print(f\"  Scale pos weight: {aggressive_pos_weight:.2f}\")\n",
    "\n",
    "        oof_preds[test_index] = y_pred_probs\n",
    "\n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(y_test, y_pred_probs)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else np.nan\n",
    "\n",
    "        # Calculate F1-score\n",
    "        f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else np.nan\n",
    "\n",
    "        # Append metrics for the fold\n",
    "        metrics['AUC'].append(auc)\n",
    "        metrics['Sensitivity'].append(sensitivity)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "        metrics['PPV'].append(ppv)\n",
    "        metrics['NPV'].append(npv)\n",
    "        metrics['F1-score'].append(f1)\n",
    "\n",
    "        # Collect data for plotting ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n",
    "        fpr_list.append(fpr)\n",
    "        tpr_list.append(tpr)\n",
    "\n",
    "        fold_number += 1\n",
    "\n",
    "    # Calculate mean and 95% CI for each metric\n",
    "    def compute_mean_ci(values):\n",
    "        mean = np.mean(values)\n",
    "        lower = np.percentile(values, 2.5)\n",
    "        upper = np.percentile(values, 97.5)\n",
    "        return mean, (lower, upper)\n",
    "\n",
    "    for metric, values in metrics.items():\n",
    "        mean, ci = compute_mean_ci(values)\n",
    "        print(f\"{metric}: {mean:.4f} (95% CI: {ci[0]:.4f} - {ci[1]:.4f})\")\n",
    "\n",
    "    # Calculate and display average F1-score\n",
    "    avg_f1 = np.mean(metrics['F1-score'])\n",
    "    print(f\"F1-Score Across Folds: {avg_f1:.4f}\")\n",
    "\n",
    "    # Plot ROC curve for each fold\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(n_splits):\n",
    "        plt.plot(fpr_list[i], tpr_list[i], label=f'Fold {i+1} (AUC = {metrics[\"AUC\"][i]:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f\"ROC Curve of {df_name} using LightGBM\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 1800 samples (in df_training_1980) as training set\n",
    "model_LGBM_1980, oof_preds_LGBM_1980 = train_LightGBM(df_training_1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 3600 samples (in df_training_3780) as training set\n",
    "model_LGBM_3780, oof_preds_LGBM_3780 = train_LightGBM(df_training_3780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 5400 samples (in df_training_5580) as training set\n",
    "model_LGBM_5580, oof_preds_LGBM_5580 = train_LightGBM(df_training_5580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 38955 samples (in df_training) as training set\n",
    "model_LGBM, oof_preds_LGBM = train_LightGBM(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfEnsH9BAuy3",
    "outputId": "c42aa3c8-8fe9-4ff4-b31d-8cfe904aa8c2"
   },
   "outputs": [],
   "source": [
    "model_LGBM_360, oof_preds_LGBM_360 = train_LightGBM(df_training_360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6W5Hp96CAuy4"
   },
   "outputs": [],
   "source": [
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {gpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Weighted Focal Loss Class ---\n",
    "class WeightedFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2.0, weight=None):\n",
    "        super(WeightedFocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight \n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.weight)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt)**self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# --- 2. Main Training Function ---\n",
    "def train_dnn(df, epochs=250, batch_size=128, n_splits=5, learning_rate=0.003):\n",
    "    # Separate features and target variable\n",
    "    X = df.drop('CLASSIFIER', axis=1).values\n",
    "    y = df['CLASSIFIER'].values\n",
    "\n",
    "    # Cross-validation setup\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    metrics = {'AUC': [], 'Sensitivity': [], 'Specificity': [], 'PPV': [], 'NPV': [], 'F1-score': []}\n",
    "\n",
    "    fold_number = 1\n",
    "    fpr_list = []\n",
    "    tpr_list = []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Training DNN with {X.shape[0]} samples on {gpu_count} GPU(s):\")\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # Extract df's variable name for plot title\n",
    "        df_name = [name for name, val in globals().items() if val is df][0]\n",
    "\n",
    "        # Split data\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train = torch.tensor(X_train_fold, dtype=torch.float32).to(device)\n",
    "        y_train = torch.tensor(y_train_fold, dtype=torch.long).to(device)\n",
    "        X_test = torch.tensor(X_test_fold, dtype=torch.float32).to(device)\n",
    "        y_test = torch.tensor(y_test_fold, dtype=torch.long).to(device)\n",
    "\n",
    "        # Create DataLoaders (Fixed NameError)\n",
    "        train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Define the DNN model\n",
    "        input_size = X_train.shape[1]\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        ).to(device)\n",
    "\n",
    "        # Wrap for Multi-GPU\n",
    "        if gpu_count > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        # Cost-Sensitive Weights\n",
    "        class_counts = np.bincount(y_train_fold)\n",
    "        cw = torch.tensor([1.0, class_counts[0] / class_counts[1]], dtype=torch.float32).to(device)\n",
    "\n",
    "        criterion = WeightedFocalLoss(alpha=1, gamma=2.0, weight=cw)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-5)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.8)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Evaluation for the fold\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred_probs = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                y_pred_probs.extend(probs)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Dynamic Thresholding for Sensitivity Fix\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        best_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        y_pred = (np.array(y_pred_probs) >= best_threshold).astype(int)\n",
    "        oof_preds[test_index] = y_pred_probs\n",
    "\n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(y_true, y_pred_probs)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else np.nan\n",
    "        f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else np.nan\n",
    "\n",
    "        metrics['AUC'].append(auc)\n",
    "        metrics['Sensitivity'].append(sensitivity)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "        metrics['PPV'].append(ppv)\n",
    "        metrics['NPV'].append(npv)\n",
    "        metrics['F1-score'].append(f1)\n",
    "\n",
    "        fpr_list.append(fpr)\n",
    "        tpr_list.append(tpr)\n",
    "        fold_number += 1\n",
    "\n",
    "    # Calculate mean and 95% CI\n",
    "    def compute_mean_ci(values):\n",
    "        mean = np.mean(values)\n",
    "        lower = np.percentile(values, 2.5)\n",
    "        upper = np.percentile(values, 97.5)\n",
    "        return mean, (lower, upper)\n",
    "\n",
    "    for metric, values in metrics.items():\n",
    "        mean, ci = compute_mean_ci(values)\n",
    "        print(f\"{metric}: {mean:.4f} (95% CI: {ci[0]:.4f} - {ci[1]:.4f})\")\n",
    "\n",
    "    # Plot ROC curve (Original format)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(n_splits):\n",
    "        plt.plot(fpr_list[i], tpr_list[i], label=f'Fold {i+1} (AUC = {metrics[\"AUC\"][i]:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f\"ROC Curve of {df_name} using DNN\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return model, oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 1800 samples (in df_training_1980) as training set\n",
    "model_DNN_1980, oof_preds_DNN_1980 = train_dnn(df_training_1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 3600 samples (in df_training_3780) as training set\n",
    "model_DNN_3780, oof_preds_DNN_3780 = train_dnn(df_training_3780)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 180 + 5400 samples (in df_training_5580) as training set\n",
    "model_DNN_5580, oof_preds_DNN_5580 = train_dnn(df_training_5580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-31T03:18:35.630Z",
     "iopub.execute_input": "2025-12-31T03:11:25.150013Z",
     "iopub.status.busy": "2025-12-31T03:11:25.149399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use 180 + 38955 samples (in df_training) as training set\n",
    "model_DNN, oof_preds_DNN = train_dnn(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icpnw8NPAuy_"
   },
   "outputs": [],
   "source": [
    "model_DNN_360, oof_preds_DNN_360 = train_dnn(df_training_360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFcmN0gXAuy_"
   },
   "outputs": [],
   "source": [
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct ensemble learning with 8180 and 360 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = meta-feature matrix (3 columns: RF, LGBM, DNN predictions)\n",
    "oof_preds_X_360 = np.column_stack([oof_preds_RF_360, oof_preds_LGBM_360, oof_preds_DNN_360])\n",
    "oof_preds_X_1980 = np.column_stack([oof_preds_RF_1980, oof_preds_LGBM_1980, oof_preds_DNN_1980])\n",
    "oof_preds_X_3780 = np.column_stack([oof_preds_RF_3780, oof_preds_LGBM_3780, oof_preds_DNN_3780])\n",
    "oof_preds_X_5580 = np.column_stack([oof_preds_RF_5580, oof_preds_LGBM_5580, oof_preds_DNN_5580])\n",
    "\n",
    "\n",
    "# y = true labels for training data\n",
    "y_meta_360 = df_training_360['CLASSIFIER'].values\n",
    "y_meta_1980 = df_training_1980['CLASSIFIER'].values\n",
    "y_meta_3780 = df_training_3780['CLASSIFIER'].values\n",
    "y_meta_5580 = df_training_5580['CLASSIFIER'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the LR meta-learner\n",
    "meta_model_LR_360 = LogisticRegression(class_weight='balanced', penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "meta_model_LR_1980 = LogisticRegression(class_weight='balanced', penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "meta_model_LR_3780 = LogisticRegression(class_weight='balanced', penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "meta_model_LR_5580 = LogisticRegression(class_weight='balanced', penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "meta_model_LR = LogisticRegression(class_weight=\"balanced\", penalty=\"l2\", solver=\"lbfgs\", max_iter=1000)\n",
    "\n",
    "meta_model_LR_360.fit(oof_preds_X_360, y_meta_360)\n",
    "meta_model_LR_1980.fit(oof_preds_X_1980, y_meta_1980)\n",
    "meta_model_LR_3780.fit(oof_preds_X_3780, y_meta_3780)\n",
    "meta_model_LR_5580.fit(oof_preds_X_5580, y_meta_5580)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test features and labels for 68, 374, 714, 1054, 7382 testing sets \n",
    "X_test_68 = df_testing_68.drop('CLASSIFIER', axis=1).values\n",
    "X_test_374 = df_testing_374.drop('CLASSIFIER', axis=1).values\n",
    "X_test_714 = df_testing_714.drop('CLASSIFIER', axis=1).values\n",
    "X_test_1054 = df_testing_1054.drop('CLASSIFIER', axis=1).values\n",
    "X_test_7382 = df_testing_7382.drop('CLASSIFIER', axis=1).values\n",
    "\n",
    "# Prepare test features and labels for 68, 374, 714, 1054, 7382 testing sets of simulations\n",
    "X_test_68_sim = df_testing_68_sim.drop('CLASSIFIER', axis=1).values\n",
    "X_test_374_sim = df_testing_374_sim.drop('CLASSIFIER', axis=1).values\n",
    "X_test_714_sim = df_testing_714_sim.drop('CLASSIFIER', axis=1).values\n",
    "X_test_1054_sim = df_testing_1054_sim.drop('CLASSIFIER', axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test features and labels for classifiers\n",
    "\n",
    "# Regular\n",
    "y_test_68 = df_testing_68['CLASSIFIER'].values\n",
    "y_test_374 = df_testing_374['CLASSIFIER'].values\n",
    "y_test_714 = df_testing_714['CLASSIFIER'].values\n",
    "y_test_1054 = df_testing_1054['CLASSIFIER'].values\n",
    "y_test_7382 = df_testing_7382['CLASSIFIER'].values\n",
    "\n",
    "# Simulation\n",
    "y_test_68_sim = df_testing_68_sim['CLASSIFIER'].values\n",
    "y_test_374_sim = df_testing_374_sim['CLASSIFIER'].values\n",
    "y_test_714_sim = df_testing_714_sim['CLASSIFIER'].values\n",
    "y_test_1054_sim = df_testing_1054_sim['CLASSIFIER'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for ramdon forest\n",
    "# X_test structure: 34 +34, 34 + 340, 34 + 680, 34 + 1020, 34 + 1364, 34 + 7348  \n",
    "# Regular \n",
    "test_preds_RF_360_68 = model_RF_360.predict_proba(X_test_68)[:, 1]\n",
    "test_preds_RF_1980_68 = model_RF_1980.predict_proba(X_test_68)[:, 1]\n",
    "test_preds_RF_3780_68 = model_RF_3780.predict_proba(X_test_68)[:, 1]\n",
    "test_preds_RF_5580_68 = model_RF_5580.predict_proba(X_test_68)[:, 1]\n",
    "\n",
    "test_preds_RF_360_374 = model_RF_360.predict_proba(X_test_374)[:, 1]\n",
    "test_preds_RF_1980_374 = model_RF_1980.predict_proba(X_test_374)[:, 1]\n",
    "test_preds_RF_3780_374 = model_RF_3780.predict_proba(X_test_374)[:, 1]\n",
    "test_preds_RF_5580_374 = model_RF_5580.predict_proba(X_test_374)[:, 1]\n",
    "\n",
    "test_preds_RF_360_714 = model_RF_360.predict_proba(X_test_714)[:, 1]\n",
    "test_preds_RF_1980_714 = model_RF_1980.predict_proba(X_test_714)[:, 1]\n",
    "test_preds_RF_3780_714 = model_RF_3780.predict_proba(X_test_714)[:, 1]\n",
    "test_preds_RF_5580_714 = model_RF_5580.predict_proba(X_test_714)[:, 1]\n",
    "\n",
    "test_preds_RF_360_1054 = model_RF_360.predict_proba(X_test_1054)[:, 1]\n",
    "test_preds_RF_1980_1054 = model_RF_1980.predict_proba(X_test_1054)[:, 1]\n",
    "test_preds_RF_3780_1054 = model_RF_3780.predict_proba(X_test_1054)[:, 1]\n",
    "test_preds_RF_5580_1054 = model_RF_5580.predict_proba(X_test_1054)[:, 1]\n",
    "\n",
    "test_preds_RF_360_7382 = model_RF_360.predict_proba(X_test_7382)[:, 1]\n",
    "test_preds_RF_1980_7382 = model_RF_1980.predict_proba(X_test_7382)[:, 1]\n",
    "test_preds_RF_3780_7382 = model_RF_3780.predict_proba(X_test_7382)[:, 1]\n",
    "test_preds_RF_5580_7382 = model_RF_5580.predict_proba(X_test_7382)[:, 1]\n",
    "\n",
    "# Simulation\n",
    "test_preds_RF_360_68_sim = model_RF_360.predict_proba(X_test_68_sim)[:, 1]\n",
    "test_preds_RF_1980_68_sim = model_RF_1980.predict_proba(X_test_68_sim)[:, 1]\n",
    "test_preds_RF_3780_68_sim = model_RF_3780.predict_proba(X_test_68_sim)[:, 1]\n",
    "test_preds_RF_5580_68_sim = model_RF_5580.predict_proba(X_test_68_sim)[:, 1]\n",
    "\n",
    "test_preds_RF_360_374_sim = model_RF_360.predict_proba(X_test_374_sim)[:, 1]\n",
    "test_preds_RF_1980_374_sim = model_RF_1980.predict_proba(X_test_374_sim)[:, 1]\n",
    "test_preds_RF_3780_374_sim = model_RF_3780.predict_proba(X_test_374_sim)[:, 1]\n",
    "test_preds_RF_5580_374_sim = model_RF_5580.predict_proba(X_test_374_sim)[:, 1]\n",
    "\n",
    "test_preds_RF_360_714_sim = model_RF_360.predict_proba(X_test_714_sim)[:, 1]\n",
    "test_preds_RF_1980_714_sim = model_RF_1980.predict_proba(X_test_714_sim)[:, 1]\n",
    "test_preds_RF_3780_714_sim = model_RF_3780.predict_proba(X_test_714_sim)[:, 1]\n",
    "test_preds_RF_5580_714_sim = model_RF_5580.predict_proba(X_test_714_sim)[:, 1]\n",
    "\n",
    "test_preds_RF_360_1054_sim = model_RF_360.predict_proba(X_test_1054_sim)[:, 1]\n",
    "test_preds_RF_1980_1054_sim = model_RF_1980.predict_proba(X_test_1054_sim)[:, 1]\n",
    "test_preds_RF_3780_1054_sim = model_RF_3780.predict_proba(X_test_1054_sim)[:, 1]\n",
    "test_preds_RF_5580_1054_sim = model_RF_5580.predict_proba(X_test_1054_sim)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for LightGBM\n",
    "# X_test structure: 34 +34, 34 + 340, 34 + 680, 34 + 1020, 34 + 1364, 34 + 7348  \n",
    "# Regular \n",
    "test_preds_LGBM_360_68 = model_LGBM_360.predict_proba(X_test_68)[:, 1]\n",
    "test_preds_LGBM_1980_68 = model_LGBM_1980.predict_proba(X_test_68)[:, 1]\n",
    "test_preds_LGBM_3780_68 = model_LGBM_3780.predict_proba(X_test_68)[:, 1]\n",
    "test_preds_LGBM_5580_68 = model_LGBM_5580.predict_proba(X_test_68)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_374 = model_LGBM_360.predict_proba(X_test_374)[:, 1]\n",
    "test_preds_LGBM_1980_374 = model_LGBM_1980.predict_proba(X_test_374)[:, 1]\n",
    "test_preds_LGBM_3780_374 = model_LGBM_3780.predict_proba(X_test_374)[:, 1]\n",
    "test_preds_LGBM_5580_374 = model_LGBM_5580.predict_proba(X_test_374)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_714 = model_LGBM_360.predict_proba(X_test_714)[:, 1]\n",
    "test_preds_LGBM_1980_714 = model_LGBM_1980.predict_proba(X_test_714)[:, 1]\n",
    "test_preds_LGBM_3780_714 = model_LGBM_3780.predict_proba(X_test_714)[:, 1]\n",
    "test_preds_LGBM_5580_714 = model_LGBM_5580.predict_proba(X_test_714)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_1054 = model_LGBM_360.predict_proba(X_test_1054)[:, 1]\n",
    "test_preds_LGBM_1980_1054 = model_LGBM_1980.predict_proba(X_test_1054)[:, 1]\n",
    "test_preds_LGBM_3780_1054 = model_LGBM_3780.predict_proba(X_test_1054)[:, 1]\n",
    "test_preds_LGBM_5580_1054 = model_LGBM_5580.predict_proba(X_test_1054)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_7382 = model_LGBM_360.predict_proba(X_test_7382)[:, 1]\n",
    "test_preds_LGBM_1980_7382 = model_LGBM_1980.predict_proba(X_test_7382)[:, 1]\n",
    "test_preds_LGBM_3780_7382 = model_LGBM_3780.predict_proba(X_test_7382)[:, 1]\n",
    "test_preds_LGBM_5580_7382 = model_LGBM_5580.predict_proba(X_test_7382)[:, 1]\n",
    "\n",
    "# Simulation\n",
    "test_preds_LGBM_360_68_sim = model_LGBM_360.predict_proba(X_test_68_sim)[:, 1]\n",
    "test_preds_LGBM_1980_68_sim = model_LGBM_1980.predict_proba(X_test_68_sim)[:, 1]\n",
    "test_preds_LGBM_3780_68_sim = model_LGBM_3780.predict_proba(X_test_68_sim)[:, 1]\n",
    "test_preds_LGBM_5580_68_sim = model_LGBM_5580.predict_proba(X_test_68_sim)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_374_sim = model_LGBM_360.predict_proba(X_test_374_sim)[:, 1]\n",
    "test_preds_LGBM_1980_374_sim = model_LGBM_1980.predict_proba(X_test_374_sim)[:, 1]\n",
    "test_preds_LGBM_3780_374_sim = model_LGBM_3780.predict_proba(X_test_374_sim)[:, 1]\n",
    "test_preds_LGBM_5580_374_sim = model_LGBM_5580.predict_proba(X_test_374_sim)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_714_sim = model_LGBM_360.predict_proba(X_test_714_sim)[:, 1]\n",
    "test_preds_LGBM_1980_714_sim = model_LGBM_1980.predict_proba(X_test_714_sim)[:, 1]\n",
    "test_preds_LGBM_3780_714_sim = model_LGBM_3780.predict_proba(X_test_714_sim)[:, 1]\n",
    "test_preds_LGBM_5580_714_sim = model_LGBM_5580.predict_proba(X_test_714_sim)[:, 1]\n",
    "\n",
    "test_preds_LGBM_360_1054_sim = model_LGBM_360.predict_proba(X_test_1054_sim)[:, 1]\n",
    "test_preds_LGBM_1980_1054_sim = model_LGBM_1980.predict_proba(X_test_1054_sim)[:, 1]\n",
    "test_preds_LGBM_3780_1054_sim = model_LGBM_3780.predict_proba(X_test_1054_sim)[:, 1]\n",
    "test_preds_LGBM_5580_1054_sim = model_LGBM_5580.predict_proba(X_test_1054_sim)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 360 DNNs, run forward pass and extract softmax scores\n",
    "X_test_tensor_68 = torch.tensor(X_test_68, dtype=torch.float32).to(device)\n",
    "X_test_tensor_374 = torch.tensor(X_test_374, dtype=torch.float32).to(device)\n",
    "X_test_tensor_714 = torch.tensor(X_test_714, dtype=torch.float32).to(device)\n",
    "X_test_tensor_1054 = torch.tensor(X_test_1054, dtype=torch.float32).to(device)\n",
    "X_test_tensor_7382 = torch.tensor(X_test_7382, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor_68_sim = torch.tensor(X_test_68_sim, dtype=torch.float32).to(device)\n",
    "X_test_tensor_374_sim = torch.tensor(X_test_374_sim, dtype=torch.float32).to(device)\n",
    "X_test_tensor_714_sim = torch.tensor(X_test_714_sim, dtype=torch.float32).to(device)\n",
    "X_test_tensor_1054_sim = torch.tensor(X_test_1054_sim, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cost-sensitive DNN setting\n",
    "# X_test structure: 34 +34, 34 + 340, 34 + 680, 34 + 1020, 34 + 1364, 34 + 7348  \n",
    "model_DNN_360.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds_DNN_360_68 = torch.softmax(model_DNN_360(X_test_tensor_68), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_374 = torch.softmax(model_DNN_360(X_test_tensor_374), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_714 = torch.softmax(model_DNN_360(X_test_tensor_714), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_1054 = torch.softmax(model_DNN_360(X_test_tensor_1054), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_7382 = torch.softmax(model_DNN_360(X_test_tensor_7382), dim=1)[:, 1].cpu().numpy()\n",
    "    \n",
    "    test_preds_DNN_360_68_sim = torch.softmax(model_DNN_360(X_test_tensor_68_sim), dim=1)[:, 1].cpu().numpy() \n",
    "    test_preds_DNN_360_374_sim = torch.softmax(model_DNN_360(X_test_tensor_374_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_714_sim = torch.softmax(model_DNN_360(X_test_tensor_714_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_1054_sim = torch.softmax(model_DNN_360(X_test_tensor_1054_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    \n",
    "\n",
    "model_DNN_1980.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds_DNN_1980_68 = torch.softmax(model_DNN_1980(X_test_tensor_68), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_374 = torch.softmax(model_DNN_1980(X_test_tensor_374), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_714 = torch.softmax(model_DNN_1980(X_test_tensor_714), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_1054 = torch.softmax(model_DNN_1980(X_test_tensor_1054), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_7382 = torch.softmax(model_DNN_1980(X_test_tensor_7382), dim=1)[:, 1].cpu().numpy()\n",
    "    \n",
    "    test_preds_DNN_1980_68_sim = torch.softmax(model_DNN_1980(X_test_tensor_68_sim), dim=1)[:, 1].cpu().numpy() \n",
    "    test_preds_DNN_1980_374_sim = torch.softmax(model_DNN_1980(X_test_tensor_374_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_714_sim = torch.softmax(model_DNN_1980(X_test_tensor_714_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_1054_sim = torch.softmax(model_DNN_1980(X_test_tensor_1054_sim), dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "\n",
    "model_DNN_3780.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds_DNN_3780_68 = torch.softmax(model_DNN_3780(X_test_tensor_68), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_374 = torch.softmax(model_DNN_3780(X_test_tensor_374), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_714 = torch.softmax(model_DNN_3780(X_test_tensor_714), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_1054 = torch.softmax(model_DNN_3780(X_test_tensor_1054), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_7382 = torch.softmax(model_DNN_3780(X_test_tensor_7382), dim=1)[:, 1].cpu().numpy()\n",
    "    \n",
    "    test_preds_DNN_3780_68_sim = torch.softmax(model_DNN_3780(X_test_tensor_68_sim), dim=1)[:, 1].cpu().numpy() \n",
    "    test_preds_DNN_3780_374_sim = torch.softmax(model_DNN_3780(X_test_tensor_374_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_714_sim = torch.softmax(model_DNN_3780(X_test_tensor_714_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_1054_sim = torch.softmax(model_DNN_3780(X_test_tensor_1054_sim), dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "model_DNN_5580.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds_DNN_5580_68 = torch.softmax(model_DNN_5580(X_test_tensor_68), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_374 = torch.softmax(model_DNN_5580(X_test_tensor_374), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_714 = torch.softmax(model_DNN_5580(X_test_tensor_714), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_1054 = torch.softmax(model_DNN_5580(X_test_tensor_1054), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_7382 = torch.softmax(model_DNN_5580(X_test_tensor_7382), dim=1)[:, 1].cpu().numpy()\n",
    "    \n",
    "    test_preds_DNN_5580_68_sim = torch.softmax(model_DNN_5580(X_test_tensor_68_sim), dim=1)[:, 1].cpu().numpy() \n",
    "    test_preds_DNN_5580_374_sim = torch.softmax(model_DNN_5580(X_test_tensor_374_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_714_sim = torch.softmax(model_DNN_5580(X_test_tensor_714_sim), dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_1054_sim = torch.softmax(model_DNN_5580(X_test_tensor_1054_sim), dim=1)[:, 1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack models predictions for testing set\n",
    "\n",
    "# Regular\n",
    "test_preds_stack_360_68 = np.column_stack([test_preds_RF_360_68, test_preds_LGBM_360_68, test_preds_DNN_360_68])\n",
    "test_preds_stack_1980_68 = np.column_stack([test_preds_RF_1980_68, test_preds_LGBM_1980_68, test_preds_DNN_1980_68])\n",
    "test_preds_stack_3780_68 = np.column_stack([test_preds_RF_3780_68, test_preds_LGBM_3780_68, test_preds_DNN_3780_68])\n",
    "test_preds_stack_5580_68 = np.column_stack([test_preds_RF_5580_68, test_preds_LGBM_5580_68, test_preds_DNN_5580_68])\n",
    "\n",
    "test_preds_stack_360_374 = np.column_stack([test_preds_RF_360_374, test_preds_LGBM_360_374, test_preds_DNN_360_374])\n",
    "test_preds_stack_1980_374 = np.column_stack([test_preds_RF_1980_374, test_preds_LGBM_1980_374, test_preds_DNN_1980_374])\n",
    "test_preds_stack_3780_374 = np.column_stack([test_preds_RF_3780_374, test_preds_LGBM_3780_374, test_preds_DNN_3780_374])\n",
    "test_preds_stack_5580_374 = np.column_stack([test_preds_RF_5580_374, test_preds_LGBM_5580_374, test_preds_DNN_5580_374])\n",
    "\n",
    "test_preds_stack_360_714 = np.column_stack([test_preds_RF_360_714, test_preds_LGBM_360_714, test_preds_DNN_360_714])\n",
    "test_preds_stack_1980_714 = np.column_stack([test_preds_RF_1980_714, test_preds_LGBM_1980_714, test_preds_DNN_1980_714])\n",
    "test_preds_stack_3780_714 = np.column_stack([test_preds_RF_3780_714, test_preds_LGBM_3780_714, test_preds_DNN_3780_714])\n",
    "test_preds_stack_5580_714 = np.column_stack([test_preds_RF_5580_714, test_preds_LGBM_5580_714, test_preds_DNN_5580_714])\n",
    "\n",
    "test_preds_stack_360_1054 = np.column_stack([test_preds_RF_360_1054, test_preds_LGBM_360_1054, test_preds_DNN_360_1054])\n",
    "test_preds_stack_1980_1054 = np.column_stack([test_preds_RF_1980_1054, test_preds_LGBM_1980_1054, test_preds_DNN_1980_1054])\n",
    "test_preds_stack_3780_1054 = np.column_stack([test_preds_RF_3780_1054, test_preds_LGBM_3780_1054, test_preds_DNN_3780_1054])\n",
    "test_preds_stack_5580_1054 = np.column_stack([test_preds_RF_5580_1054, test_preds_LGBM_5580_1054, test_preds_DNN_5580_1054])\n",
    "\n",
    "test_preds_stack_360_7382 = np.column_stack([test_preds_RF_360_7382, test_preds_LGBM_360_7382, test_preds_DNN_360_7382])\n",
    "test_preds_stack_1980_7382 = np.column_stack([test_preds_RF_1980_7382, test_preds_LGBM_1980_7382, test_preds_DNN_1980_7382])\n",
    "test_preds_stack_3780_7382 = np.column_stack([test_preds_RF_3780_7382, test_preds_LGBM_3780_7382, test_preds_DNN_3780_7382])\n",
    "test_preds_stack_5580_7382 = np.column_stack([test_preds_RF_5580_7382, test_preds_LGBM_5580_7382, test_preds_DNN_5580_7382])\n",
    "\n",
    "# Simulation\n",
    "test_preds_stack_360_68_sim = np.column_stack([test_preds_RF_360_68_sim, test_preds_LGBM_360_68_sim, test_preds_DNN_360_68_sim])\n",
    "test_preds_stack_1980_68_sim = np.column_stack([test_preds_RF_1980_68_sim, test_preds_LGBM_1980_68_sim, test_preds_DNN_1980_68_sim])\n",
    "test_preds_stack_3780_68_sim = np.column_stack([test_preds_RF_3780_68_sim, test_preds_LGBM_3780_68_sim, test_preds_DNN_3780_68_sim])\n",
    "test_preds_stack_5580_68_sim = np.column_stack([test_preds_RF_5580_68_sim, test_preds_LGBM_5580_68_sim, test_preds_DNN_5580_68_sim])\n",
    "\n",
    "test_preds_stack_360_374_sim = np.column_stack([test_preds_RF_360_374_sim, test_preds_LGBM_360_374_sim, test_preds_DNN_360_374_sim])\n",
    "test_preds_stack_1980_374_sim = np.column_stack([test_preds_RF_1980_374_sim, test_preds_LGBM_1980_374_sim, test_preds_DNN_1980_374_sim])\n",
    "test_preds_stack_3780_374_sim = np.column_stack([test_preds_RF_3780_374_sim, test_preds_LGBM_3780_374_sim, test_preds_DNN_3780_374_sim])\n",
    "test_preds_stack_5580_374_sim = np.column_stack([test_preds_RF_5580_374_sim, test_preds_LGBM_5580_374_sim, test_preds_DNN_5580_374_sim])\n",
    "\n",
    "test_preds_stack_360_714_sim = np.column_stack([test_preds_RF_360_714_sim, test_preds_LGBM_360_714_sim, test_preds_DNN_360_714_sim])\n",
    "test_preds_stack_1980_714_sim = np.column_stack([test_preds_RF_1980_714_sim, test_preds_LGBM_1980_714_sim, test_preds_DNN_1980_714_sim])\n",
    "test_preds_stack_3780_714_sim = np.column_stack([test_preds_RF_3780_714_sim, test_preds_LGBM_3780_714_sim, test_preds_DNN_3780_714_sim])\n",
    "test_preds_stack_5580_714_sim = np.column_stack([test_preds_RF_5580_714_sim, test_preds_LGBM_5580_714_sim, test_preds_DNN_5580_714_sim])\n",
    "\n",
    "test_preds_stack_360_1054_sim = np.column_stack([test_preds_RF_360_1054_sim, test_preds_LGBM_360_1054_sim, test_preds_DNN_360_1054_sim])\n",
    "test_preds_stack_1980_1054_sim = np.column_stack([test_preds_RF_1980_1054_sim, test_preds_LGBM_1980_1054_sim, test_preds_DNN_1980_1054_sim])\n",
    "test_preds_stack_3780_1054_sim = np.column_stack([test_preds_RF_3780_1054_sim, test_preds_LGBM_3780_1054_sim, test_preds_DNN_3780_1054_sim])\n",
    "test_preds_stack_5580_1054_sim = np.column_stack([test_preds_RF_5580_1054_sim, test_preds_LGBM_5580_1054_sim, test_preds_DNN_5580_1054_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict final probabilities from LR meta-model\n",
    "\n",
    "# Regular\n",
    "final_probs_LR_360_68 = meta_model_LR_360.predict_proba(test_preds_stack_360_68)[:, 1]\n",
    "final_probs_LR_1980_68 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_68)[:, 1]\n",
    "final_probs_LR_3780_68 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_68)[:, 1]\n",
    "final_probs_LR_5580_68 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_68)[:, 1]\n",
    "\n",
    "final_probs_LR_360_374 = meta_model_LR_360.predict_proba(test_preds_stack_360_374)[:, 1]\n",
    "final_probs_LR_1980_374 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_374)[:, 1]\n",
    "final_probs_LR_3780_374 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_374)[:, 1]\n",
    "final_probs_LR_5580_374 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_374)[:, 1]\n",
    "\n",
    "final_probs_LR_360_714 = meta_model_LR_360.predict_proba(test_preds_stack_360_714)[:, 1]\n",
    "final_probs_LR_1980_714 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_714)[:, 1]\n",
    "final_probs_LR_3780_714 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_714)[:, 1]\n",
    "final_probs_LR_5580_714 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_714)[:, 1]\n",
    "\n",
    "final_probs_LR_360_1054 = meta_model_LR_360.predict_proba(test_preds_stack_360_1054)[:, 1]\n",
    "final_probs_LR_1980_1054 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_1054)[:, 1]\n",
    "final_probs_LR_3780_1054 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_1054)[:, 1]\n",
    "final_probs_LR_5580_1054 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_1054)[:, 1]\n",
    "\n",
    "final_probs_LR_360_7382 = meta_model_LR_360.predict_proba(test_preds_stack_360_7382)[:, 1]\n",
    "final_probs_LR_1980_7382 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_7382)[:, 1]\n",
    "final_probs_LR_3780_7382 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_7382)[:, 1]\n",
    "final_probs_LR_5580_7382 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_7382)[:, 1]\n",
    "\n",
    "\n",
    "# Simulation\n",
    "final_probs_LR_360_68_sim = meta_model_LR_360.predict_proba(test_preds_stack_360_68_sim)[:, 1]\n",
    "final_probs_LR_1980_68_sim = meta_model_LR_1980.predict_proba(test_preds_stack_1980_68_sim)[:, 1]\n",
    "final_probs_LR_3780_68_sim = meta_model_LR_3780.predict_proba(test_preds_stack_3780_68_sim)[:, 1]\n",
    "final_probs_LR_5580_68_sim = meta_model_LR_5580.predict_proba(test_preds_stack_5580_68_sim)[:, 1]\n",
    "\n",
    "final_probs_LR_360_374_sim = meta_model_LR_360.predict_proba(test_preds_stack_360_374_sim)[:, 1]\n",
    "final_probs_LR_1980_374_sim = meta_model_LR_1980.predict_proba(test_preds_stack_1980_374_sim)[:, 1]\n",
    "final_probs_LR_3780_374_sim = meta_model_LR_3780.predict_proba(test_preds_stack_3780_374_sim)[:, 1]\n",
    "final_probs_LR_5580_374_sim = meta_model_LR_5580.predict_proba(test_preds_stack_5580_374_sim)[:, 1]\n",
    "\n",
    "final_probs_LR_360_714_sim = meta_model_LR_360.predict_proba(test_preds_stack_360_714_sim)[:, 1]\n",
    "final_probs_LR_1980_714_sim = meta_model_LR_1980.predict_proba(test_preds_stack_1980_714_sim)[:, 1]\n",
    "final_probs_LR_3780_714_sim = meta_model_LR_3780.predict_proba(test_preds_stack_3780_714_sim)[:, 1]\n",
    "final_probs_LR_5580_714_sim = meta_model_LR_5580.predict_proba(test_preds_stack_5580_714_sim)[:, 1]\n",
    "\n",
    "final_probs_LR_360_1054_sim = meta_model_LR_360.predict_proba(test_preds_stack_360_1054_sim)[:, 1]\n",
    "final_probs_LR_1980_1054_sim = meta_model_LR_1980.predict_proba(test_preds_stack_1980_1054_sim)[:, 1]\n",
    "final_probs_LR_3780_1054_sim = meta_model_LR_3780.predict_proba(test_preds_stack_3780_1054_sim)[:, 1]\n",
    "final_probs_LR_5580_1054_sim = meta_model_LR_5580.predict_proba(test_preds_stack_5580_1054_sim)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds\n",
    "# Regular\n",
    "final_preds_LR_360_68 = (final_probs_LR_360_68 >= 0.5).astype(int)\n",
    "final_preds_LR_1980_68 = (final_probs_LR_1980_68 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_68 = (final_probs_LR_3780_68 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_68 = (final_probs_LR_5580_68 >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_374 = (final_probs_LR_360_374 >= 0.5).astype(int)\n",
    "final_preds_LR_1980_374 = (final_probs_LR_1980_374 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_374 = (final_probs_LR_3780_374 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_374 = (final_probs_LR_5580_374 >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_714 = (final_probs_LR_360_714 >= 0.5).astype(int)\n",
    "final_preds_LR_1980_714 = (final_probs_LR_1980_714 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_714 = (final_probs_LR_3780_714 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_714 = (final_probs_LR_5580_714 >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_1054 = (final_probs_LR_360_1054 >= 0.5).astype(int)\n",
    "final_preds_LR_1980_1054 = (final_probs_LR_1980_1054 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_1054 = (final_probs_LR_3780_1054 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_1054 = (final_probs_LR_5580_1054 >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_7382 = (final_probs_LR_360_7382 >= 0.5).astype(int)\n",
    "final_preds_LR_1980_7382 = (final_probs_LR_1980_7382 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_7382 = (final_probs_LR_3780_7382 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_7382 = (final_probs_LR_5580_7382 >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Simulation\n",
    "final_preds_LR_360_68_sim = (final_probs_LR_360_68_sim >= 0.5).astype(int)\n",
    "final_preds_LR_1980_68_sim = (final_probs_LR_1980_68_sim >= 0.5).astype(int)\n",
    "final_preds_LR_3780_68_sim = (final_probs_LR_3780_68_sim >= 0.5).astype(int)\n",
    "final_preds_LR_5580_68_sim = (final_probs_LR_5580_68_sim >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_374_sim = (final_probs_LR_360_374_sim >= 0.5).astype(int)\n",
    "final_preds_LR_1980_374_sim = (final_probs_LR_1980_374_sim >= 0.5).astype(int)\n",
    "final_preds_LR_3780_374_sim = (final_probs_LR_3780_374_sim >= 0.5).astype(int)\n",
    "final_preds_LR_5580_374_sim = (final_probs_LR_5580_374_sim >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_714_sim = (final_probs_LR_360_714_sim >= 0.5).astype(int)\n",
    "final_preds_LR_1980_714_sim = (final_probs_LR_1980_714_sim >= 0.5).astype(int)\n",
    "final_preds_LR_3780_714_sim = (final_probs_LR_3780_714_sim >= 0.5).astype(int)\n",
    "final_preds_LR_5580_714_sim = (final_probs_LR_5580_714_sim >= 0.5).astype(int)\n",
    "\n",
    "final_preds_LR_360_1054_sim = (final_probs_LR_360_1054_sim >= 0.5).astype(int)\n",
    "final_preds_LR_1980_1054_sim = (final_probs_LR_1980_1054_sim >= 0.5).astype(int)\n",
    "final_preds_LR_3780_1054_sim = (final_probs_LR_3780_1054_sim >= 0.5).astype(int)\n",
    "final_preds_LR_5580_1054_sim = (final_probs_LR_5580_1054_sim >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report tables\n",
    "# Regular\n",
    "print(\"Stacking Ensemble AUC of 360_68:\", roc_auc_score(y_test_68, final_probs_LR_360_68))\n",
    "print(\"Stacking Ensemble AUC of 1980_68:\", roc_auc_score(y_test_68, final_probs_LR_1980_68))\n",
    "print(\"Stacking Ensemble AUC of 3780_68\", roc_auc_score(y_test_68, final_probs_LR_3780_68))\n",
    "print(\"Stacking Ensemble AUC of 5580_68:\\n\", roc_auc_score(y_test_68, final_probs_LR_5580_68))\n",
    "\n",
    "print(\"Classification Report of 360_374:\\n\", classification_report(y_test_374, final_preds_LR_360_374))\n",
    "print(\"Classification Report of 1980_374:\\n\", classification_report(y_test_374, final_preds_LR_1980_374))\n",
    "print(\"Classification Report of 3780_374:\\n\", classification_report(y_test_374, final_preds_LR_3780_374))\n",
    "print(\"Classification Report of 5580_374:\\n\", classification_report(y_test_374, final_preds_LR_5580_374))\n",
    "\n",
    "print(\"Stacking Ensemble AUC of 360_714:\", roc_auc_score(y_test_714, final_probs_LR_360_714))\n",
    "print(\"Stacking Ensemble AUC of 1980_714:\", roc_auc_score(y_test_714, final_probs_LR_1980_714))\n",
    "print(\"Stacking Ensemble AUC of 3780_714:\", roc_auc_score(y_test_714, final_probs_LR_3780_714))\n",
    "print(\"Stacking Ensemble AUC of 5580_714:\\n\", roc_auc_score(y_test_714, final_probs_LR_5580_714))\n",
    "\n",
    "print(\"Classification Report of 360_714:\\n\", classification_report(y_test_714, final_preds_LR_360_714))\n",
    "print(\"Classification Report of 1980_714:\\n\", classification_report(y_test_714, final_preds_LR_1980_714))\n",
    "print(\"Classification Report of 3780_714:\\n\", classification_report(y_test_714, final_preds_LR_3780_714))\n",
    "print(\"Classification Report of 5580_714:\\n\", classification_report(y_test_714, final_preds_LR_5580_714))\n",
    "\n",
    "print(\"Stacking Ensemble AUC of 360_1054:\", roc_auc_score(y_test_1054, final_probs_LR_360_1054))\n",
    "print(\"Stacking Ensemble AUC of 1980_1054:\", roc_auc_score(y_test_1054, final_probs_LR_1980_1054))\n",
    "print(\"Stacking Ensemble AUC of 3780_1054:\", roc_auc_score(y_test_1054, final_probs_LR_3780_1054))\n",
    "print(\"Stacking Ensemble AUC of 5580_1054:\\n\", roc_auc_score(y_test_1054, final_probs_LR_5580_1054))\n",
    "\n",
    "print(\"Classification Report of 360_1054:\\n\", classification_report(y_test_1054, final_preds_LR_360_1054))\n",
    "print(\"Classification Report of 1980_1054:\\n\", classification_report(y_test_1054, final_preds_LR_1980_1054))\n",
    "print(\"Classification Report of 3780_1054:\\n\", classification_report(y_test_1054, final_preds_LR_3780_1054))\n",
    "print(\"Classification Report of 5580_1054:\\n\", classification_report(y_test_1054, final_preds_LR_5580_1054))\n",
    "\n",
    "print(\"Stacking Ensemble AUC of 360_7382:\", roc_auc_score(y_test_7382, final_probs_LR_360_7382))\n",
    "print(\"Stacking Ensemble AUC of 1980_7382:\", roc_auc_score(y_test_7382, final_probs_LR_1980_7382))\n",
    "print(\"Stacking Ensemble AUC of 3780_7382:\", roc_auc_score(y_test_7382, final_probs_LR_3780_7382))\n",
    "print(\"Stacking Ensemble AUC of 5580_7382:\\n\", roc_auc_score(y_test_7382, final_probs_LR_5580_7382))\n",
    "\n",
    "print(\"Classification Report of 360_7382:\\n\", classification_report(y_test_7382, final_preds_LR_360_7382))\n",
    "print(\"Classification Report of 1980_7382:\\n\", classification_report(y_test_7382, final_preds_LR_1980_7382))\n",
    "print(\"Classification Report of 3780_7382:\\n\", classification_report(y_test_7382, final_preds_LR_3780_7382))\n",
    "print(\"Classification Report of 5580_7382:\\n\", classification_report(y_test_7382, final_preds_LR_5580_7382))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation report\n",
    "print(\"Stacking Ensemble AUC of 360_68_sim:\", roc_auc_score(y_test_68, final_probs_LR_360_68_sim))\n",
    "print(\"Stacking Ensemble AUC of 1980_68_sim:\", roc_auc_score(y_test_68, final_probs_LR_1980_68_sim))\n",
    "print(\"Stacking Ensemble AUC of 3780_68_sim:\", roc_auc_score(y_test_68, final_probs_LR_3780_68_sim))\n",
    "print(\"Stacking Ensemble AUC of 5580_68_sim:\\n\", roc_auc_score(y_test_68, final_probs_LR_5580_68_sim))\n",
    "\n",
    "print(\"Classification Report of 360_374_sim:\\n\", classification_report(y_test_374, final_preds_LR_360_374_sim))\n",
    "print(\"Classification Report of 1980_374_sim:\\n\", classification_report(y_test_374, final_preds_LR_1980_374_sim))\n",
    "print(\"Classification Report of 3780_374_sim:\\n\", classification_report(y_test_374, final_preds_LR_3780_374_sim))\n",
    "print(\"Classification Report of 5580_374_sim:\\n\", classification_report(y_test_374, final_preds_LR_5580_374_sim))\n",
    "\n",
    "print(\"Stacking Ensemble AUC of 360_714_sim:\", roc_auc_score(y_test_714, final_probs_LR_360_714_sim))\n",
    "print(\"Stacking Ensemble AUC of 1980_714_sim:\", roc_auc_score(y_test_714, final_probs_LR_1980_714_sim))\n",
    "print(\"Stacking Ensemble AUC of 3780_714_sim:\", roc_auc_score(y_test_714, final_probs_LR_3780_714_sim))\n",
    "print(\"Stacking Ensemble AUC of 5580_714_sim:\\n\", roc_auc_score(y_test_714, final_probs_LR_5580_714_sim))\n",
    "\n",
    "print(\"Classification Report of 360_714_sim:\\n\", classification_report(y_test_714, final_preds_LR_360_714_sim))\n",
    "print(\"Classification Report of 1980_714_sim:\\n\", classification_report(y_test_714, final_preds_LR_1980_714_sim))\n",
    "print(\"Classification Report of 3780_714_sim:\\n\", classification_report(y_test_714, final_preds_LR_3780_714_sim))\n",
    "print(\"Classification Report of 5580_714_sim:\\n\", classification_report(y_test_714, final_preds_LR_5580_714_sim))\n",
    "\n",
    "print(\"Stacking Ensemble AUC of 360_1054_sim:\", roc_auc_score(y_test_1054, final_probs_LR_360_1054_sim))\n",
    "print(\"Stacking Ensemble AUC of 1980_1054_sim:\", roc_auc_score(y_test_1054, final_probs_LR_1980_1054_sim))\n",
    "print(\"Stacking Ensemble AUC of 3780_1054_sim:\", roc_auc_score(y_test_1054, final_probs_LR_3780_1054_sim))\n",
    "print(\"Stacking Ensemble AUC of 5580_1054_sim:\\n\", roc_auc_score(y_test_1054, final_probs_LR_5580_1054_sim))\n",
    "\n",
    "print(\"Classification Report of 360_1054_sim:\\n\", classification_report(y_test_1054, final_preds_LR_360_1054_sim))\n",
    "print(\"Classification Report of 1980_1054_sim:\\n\", classification_report(y_test_1054, final_preds_LR_1980_1054_sim))\n",
    "print(\"Classification Report of 3780_1054_sim:\\n\", classification_report(y_test_1054, final_preds_LR_3780_1054_sim))\n",
    "print(\"Classification Report of 5580_1054_sim:\\n\", classification_report(y_test_1054, final_preds_LR_5580_1054_sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-defining the function since kernel reset might have cleared previous definitions\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, confusion_matrix, f1_score, roc_curve\n",
    ")\n",
    "\n",
    "# Function to evaluate meta-learner with 95% CI and ROC plot\n",
    "def evaluate_meta_model_with_ci(y_true, y_prob, threshold=0.1, n_bootstrap=1000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    npv = tn / (tn + fn) if tn + fn > 0 else 0\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    aucs, sens, specs, ppvs, npvs, f1s = [], [], [], [], [], []\n",
    "\n",
    "    n = len(y_true)\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(np.arange(n), size=n, replace=True)\n",
    "        y_true_bs = y_true[indices]\n",
    "        y_prob_bs = y_prob[indices]\n",
    "        y_pred_bs = (y_prob_bs >= threshold).astype(int)\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_true_bs, y_prob_bs))\n",
    "            tn_b, fp_b, fn_b, tp_b = confusion_matrix(y_true_bs, y_pred_bs).ravel()\n",
    "            sens.append(tp_b / (tp_b + fn_b))\n",
    "            specs.append(tn_b / (tn_b + fp_b))\n",
    "            ppvs.append(tp_b / (tp_b + fp_b) if tp_b + fp_b > 0 else 0)\n",
    "            npvs.append(tn_b / (tn_b + fn_b) if tn_b + fn_b > 0 else 0)\n",
    "            f1s.append(f1_score(y_true_bs, y_pred_bs))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    def ci(data):\n",
    "        return np.mean(data), np.percentile(data, 2.5), np.percentile(data, 97.5)\n",
    "\n",
    "    metrics = {\n",
    "        'AUC': ci(aucs),\n",
    "        'Sensitivity': ci(sens),\n",
    "        'Specificity': ci(specs),\n",
    "        'PPV': ci(ppvs),\n",
    "        'NPV': ci(npvs),\n",
    "        'F1-score': ci(f1s)\n",
    "    }\n",
    "\n",
    "    for metric, (mean, lower, upper) in metrics.items():\n",
    "        print(f\"{metric}: {mean:.4f} (95% CI: {lower:.4f} - {upper:.4f})\")\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve of Stacking Meta-Learner\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_360_68 = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_360_68, threshold=0.5)\n",
    "metrics_1980_68 = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_1980_68, threshold=0.5)\n",
    "metrics_3780_68 = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_3780_68, threshold=0.5)\n",
    "metrics_5580_68 = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_5580_68, threshold=0.5)\n",
    "\n",
    "metrics_360_374 = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_360_374, threshold=0.5)\n",
    "metrics_1980_374 = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_1980_374, threshold=0.5)\n",
    "metrics_3780_374 = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_3780_374, threshold=0.5)\n",
    "metrics_5580_374 = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_5580_374, threshold=0.5)\n",
    "\n",
    "metrics_360_714 = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_360_714, threshold=0.5)\n",
    "metrics_1980_714 = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_1980_714, threshold=0.5)\n",
    "metrics_3780_714 = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_3780_714, threshold=0.5)\n",
    "metrics_5580_714 = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_5580_714, threshold=0.5)\n",
    "\n",
    "metrics_360_1054 = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_360_1054, threshold=0.5)\n",
    "metrics_1980_1054 = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_1980_1054, threshold=0.5)\n",
    "metrics_3780_1054 = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_3780_1054, threshold=0.5)\n",
    "metrics_5580_1054 = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_5580_1054, threshold=0.5)\n",
    "\n",
    "metrics_360_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_360_7382, threshold=0.5)\n",
    "metrics_1980_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_1980_7382, threshold=0.5)\n",
    "metrics_3780_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_3780_7382, threshold=0.5)\n",
    "metrics_5580_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_5580_7382, threshold=0.5)\n",
    "\n",
    "metrics_360_68_sim = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_360_68_sim, threshold=0.5)\n",
    "metrics_1980_68_sim = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_1980_68_sim, threshold=0.5)\n",
    "metrics_3780_68_sim = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_3780_68_sim, threshold=0.5)\n",
    "metrics_5580_68_sim = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_5580_68_sim, threshold=0.5)\n",
    "\n",
    "metrics_360_374_sim = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_360_374_sim, threshold=0.5)\n",
    "metrics_1980_374_sim = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_1980_374_sim, threshold=0.5)\n",
    "metrics_3780_374_sim = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_3780_374_sim, threshold=0.5)\n",
    "metrics_5580_374_sim = evaluate_meta_model_with_ci(y_test_374, final_probs_LR_5580_374_sim, threshold=0.5)\n",
    "\n",
    "metrics_360_714_sim = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_360_714_sim, threshold=0.5)\n",
    "metrics_1980_714_sim = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_1980_714_sim, threshold=0.5)\n",
    "metrics_3780_714_sim = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_3780_714_sim, threshold=0.5)\n",
    "metrics_5580_714_sim = evaluate_meta_model_with_ci(y_test_714, final_probs_LR_5580_714_sim, threshold=0.5)\n",
    "\n",
    "metrics_360_1054_sim = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_360_1054_sim, threshold=0.5)\n",
    "metrics_1980_1054_sim = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_1980_1054_sim, threshold=0.5)\n",
    "metrics_3780_1054_sim = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_3780_1054_sim, threshold=0.5)\n",
    "metrics_5580_1054_sim = evaluate_meta_model_with_ci(y_test_1054, final_probs_LR_5580_1054_sim, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T05:16:42.003729Z",
     "iopub.status.busy": "2025-12-31T05:16:42.003391Z",
     "iopub.status.idle": "2025-12-31T05:16:47.060311Z",
     "shell.execute_reply": "2025-12-31T05:16:47.059654Z",
     "shell.execute_reply.started": "2025-12-31T05:16:42.003695Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_360_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_360_7382, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T05:17:34.326025Z",
     "iopub.status.busy": "2025-12-31T05:17:34.325728Z",
     "iopub.status.idle": "2025-12-31T05:17:39.324995Z",
     "shell.execute_reply": "2025-12-31T05:17:39.324267Z",
     "shell.execute_reply.started": "2025-12-31T05:17:34.325998Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_1980_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_1980_7382, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T05:18:18.140402Z",
     "iopub.status.busy": "2025-12-31T05:18:18.140099Z",
     "iopub.status.idle": "2025-12-31T05:18:23.171175Z",
     "shell.execute_reply": "2025-12-31T05:18:23.170404Z",
     "shell.execute_reply.started": "2025-12-31T05:18:18.140375Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_3780_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_3780_7382, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T05:18:56.284751Z",
     "iopub.status.busy": "2025-12-31T05:18:56.284198Z",
     "iopub.status.idle": "2025-12-31T05:19:01.320535Z",
     "shell.execute_reply": "2025-12-31T05:19:01.319878Z",
     "shell.execute_reply.started": "2025-12-31T05:18:56.284721Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_5580_7382 = evaluate_meta_model_with_ci(y_test_7382, final_probs_LR_5580_7382, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T02:10:29.739700Z",
     "iopub.status.busy": "2025-09-12T02:10:29.739468Z",
     "iopub.status.idle": "2025-09-12T02:10:32.152978Z",
     "shell.execute_reply": "2025-09-12T02:10:32.152359Z",
     "shell.execute_reply.started": "2025-09-12T02:10:29.739684Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_360_68 = evaluate_meta_model_with_ci(y_test_68, final_probs_LR_360_68, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_360_68_sim = evaluate_meta_model_with_ci(y_test_68_sim, final_probs_LR_360_68_sim, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: yellow;\"> External Validation Section</h2>\n",
    "<p style=\"color: yellow;\">1. Check if there is data leaking;<br> 2. Eliminate features that leak information. <br> 3. Run validation with models</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#################################################################################\n",
    "# 1. Check if there is data leaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read eICU raw dataset\n",
    "meningitis_val_raw = pd.read_csv('Meningitis_val_raw.csv')\n",
    "nonmeningitis_val_raw = pd.read_csv('nonmeningitis_val_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are meningitis related columns (starting with '32') in Meningitis external validation dataset\n",
    "print(\"Checking for columns starting with '32' in meningitis_val_raw...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all column names\n",
    "all_columns_men_val = meningitis_val_raw.columns.tolist()\n",
    "\n",
    "# Find columns that start with \"32\"\n",
    "columns_starting_32_men_val = [col for col in all_columns_men_val if str(col).startswith(('320','321','322'))]\n",
    "\n",
    "print(f\"Total columns in dataset: {len(all_columns_men_val)}\")\n",
    "print(f\"Columns starting with '32': {len(columns_starting_32_men_val)}\")\n",
    "print()\n",
    "\n",
    "if columns_starting_32_men_val:\n",
    "    print(\"Found columns starting with '32':\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sort the columns for better readability\n",
    "    columns_starting_32_sorted_men_val = sorted(columns_starting_32_men_val)\n",
    "    \n",
    "    for i, col in enumerate(columns_starting_32_sorted_men_val, 1):\n",
    "        # Check how many patients have this code\n",
    "        count = meningitis_val_raw[col].sum() if col in meningitis_val_raw.columns else 0\n",
    "        percentage = (count / len(meningitis_val_raw)) * 100 if len(meningitis_val_raw) > 0 else 0\n",
    "        \n",
    "        # Check positive rate when this code is present\n",
    "        if count > 0:\n",
    "            pos_rate = meningitis_val_raw[meningitis_val_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "        else:\n",
    "            pos_rate = 0\n",
    "            \n",
    "        print(f\"{i:2d}. {str(col):<8} - Present in {int(count):4d} patients ({percentage:5.2f}%) - Pos rate: {pos_rate:.3f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Detailed analysis of '32' codes:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Group by length for better understanding\n",
    "    length_groups = {}\n",
    "    for col in columns_starting_32_sorted_men_val:\n",
    "        length = len(str(col))\n",
    "        if length not in length_groups:\n",
    "            length_groups[length] = []\n",
    "        length_groups[length].append(col)\n",
    "    \n",
    "    for length in sorted(length_groups.keys()):\n",
    "        print(f\"\\nLength {length} codes ({len(length_groups[length])} codes):\")\n",
    "        for col in length_groups[length]:\n",
    "            count = int(meningitis_val_raw[col].sum())\n",
    "            percentage = (count / len(meningitis_val_raw)) * 100\n",
    "            if count > 0:\n",
    "                pos_rate = meningitis_val_raw[meningitis_val_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - Meningitis rate: {pos_rate:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - No patients with this code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are meningitis related columns (starting with '32') in non-meningitis external validation dataset\n",
    "print(\"Checking for columns starting with '32' in nonmeningitis_val_raw...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get all column names\n",
    "all_columns_nonmen_val = nonmeningitis_val_raw.columns.tolist()\n",
    "\n",
    "# Find columns that start with \"32\"\n",
    "columns_starting_32_nonmen_val = [col for col in all_columns_nonmen_val if str(col).startswith(('320','321','322'))]\n",
    "\n",
    "print(f\"Total columns in dataset: {len(all_columns_nonmen_val)}\")\n",
    "print(f\"Columns starting with '32': {len(columns_starting_32_nonmen_val)}\")\n",
    "print()\n",
    "\n",
    "if columns_starting_32_nonmen_val:\n",
    "    print(\"Found columns starting with '32':\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Sort the columns for better readability\n",
    "    columns_starting_32_sorted_nonmen_val = sorted(columns_starting_32_nonmen_val)\n",
    "    \n",
    "    for i, col in enumerate(columns_starting_32_sorted_nonmen_val, 1):\n",
    "        # Check how many patients have this code\n",
    "        count = nonmeningitis_val_raw[col].sum() if col in nonmeningitis_val_raw.columns else 0\n",
    "        percentage = (count / len(nonmeningitis_val_raw)) * 100 if len(nonmeningitis_val_raw) > 0 else 0\n",
    "        \n",
    "        # Check positive rate when this code is present\n",
    "        if count > 0:\n",
    "            pos_rate = nonmeningitis_val_raw[nonmeningitis_val_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "        else:\n",
    "            pos_rate = 0\n",
    "            \n",
    "        print(f\"{i:2d}. {str(col):<8} - Present in {int(count):4d} patients ({percentage:5.2f}%) - Pos rate: {pos_rate:.3f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Detailed analysis of '32' codes:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Group by length for better understanding\n",
    "    length_groups = {}\n",
    "    for col in columns_starting_32_sorted_nonmen_val:\n",
    "        length = len(str(col))\n",
    "        if length not in length_groups:\n",
    "            length_groups[length] = []\n",
    "        length_groups[length].append(col)\n",
    "    \n",
    "    for length in sorted(length_groups.keys()):\n",
    "        print(f\"\\nLength {length} codes ({len(length_groups[length])} codes):\")\n",
    "        for col in length_groups[length]:\n",
    "            count = int(nonmeningitis_val_raw[col].sum())\n",
    "            percentage = (count / len(nonmeningitis_val_raw)) * 100\n",
    "            if count > 0:\n",
    "                pos_rate = nonmeningitis_val_raw[nonmeningitis_val_raw[col] == 1]['CLASSIFIER'].mean()\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - Meningitis rate: {pos_rate:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {str(col)}: {count} patients ({percentage:.2f}%) - No patients with this code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create new dataset without meningitis code columns\n",
    "meningitis_clean_val = meningitis_val_raw.drop(columns=columns_starting_32_men_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns that start with \"('320','321','322')\"\n",
    "all_columns_clean_men_val = meningitis_clean_val.columns.tolist()\n",
    "\n",
    "columns_starting_32_clean_val = [col for col in all_columns_clean_men_val if str(col).startswith(('320','321','322'))]\n",
    "\n",
    "print(f\"Total columns in dataset: {len(all_columns_clean_men_val)}\")\n",
    "print(f\"Columns starting with '('320','321','322')': {len(columns_starting_32_clean_val)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is meningitis sample in nonmeningitis_val_raw\n",
    "(nonmeningitis_val_raw[\"CLASSIFIER\"] == 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shapes\n",
    "print(meningitis_clean_val.shape)\n",
    "print(nonmeningitis_val_raw.shape)\n",
    "print(meningitis_clean_val.head)\n",
    "print(nonmeningitis_val_raw.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramdonly extract 124*10 = 1240, 124*20 = 2480, 124*30 = 3720, 124*218 = 27032 from nonmeningitis_val_raw for multiple external validation\n",
    "non_men_1240_val = nonmeningitis_val_raw.sample(n=1240, random_state=42)\n",
    "non_men_2480_val = nonmeningitis_val_raw.sample(n=2480, random_state=42)\n",
    "non_men_3720_val = nonmeningitis_val_raw.sample(n=3720, random_state=42)\n",
    "non_men_27032_val = nonmeningitis_val_raw.sample(n=27032, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(non_men_1240_val)\n",
    "print(non_men_2480_val)\n",
    "print(non_men_3720_val)\n",
    "print(non_men_27032_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate meningitis and nonmeningitis validation datasets\n",
    "val_concat_1364 = pd.concat([meningitis_clean_val, non_men_1240_val], ignore_index = True)\n",
    "val_concat_2604 = pd.concat([meningitis_clean_val, non_men_2480_val], ignore_index = True)\n",
    "val_concat_3844 = pd.concat([meningitis_clean_val, non_men_3720_val], ignore_index = True)\n",
    "val_concat_27156 = pd.concat([meningitis_clean_val, non_men_27032_val], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop SUBJECT_ID of validation sets\n",
    "val_IDdrop_1364 = val_concat_1364.drop('SUBJECT_ID', axis = 1)\n",
    "val_IDdrop_2604 = val_concat_2604.drop('SUBJECT_ID', axis = 1)\n",
    "val_IDdrop_3844 = val_concat_3844.drop('SUBJECT_ID', axis = 1)\n",
    "val_IDdrop_27156 = val_concat_27156.drop('SUBJECT_ID', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the validation set to ensure random distribution\n",
    "val_shuffled_1364 = val_IDdrop_1364.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_shuffled_2604 = val_IDdrop_2604.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_shuffled_3844 = val_IDdrop_3844.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_shuffled_27156 = val_IDdrop_27156.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_shuffled_1364.shape)\n",
    "print(val_shuffled_2604.shape)\n",
    "print(val_shuffled_3844.shape)\n",
    "print(val_shuffled_27156.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"NaN values in validation data (1364 samples):\\n\", val_shuffled_1364.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in validation data (2604 samples):\\n\", val_shuffled_2604.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in validation data (3844 samples):\\n\", val_shuffled_3844.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in validation data (27156 samples):\\n\", val_shuffled_27156.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with 0 in each dataset\n",
    "df_val_1364 = val_shuffled_1364.fillna(0)\n",
    "df_val_2064 = val_shuffled_2604.fillna(0)\n",
    "df_val_3844 = val_shuffled_3844.fillna(0)\n",
    "df_val_27156 = val_shuffled_27156.fillna(0)\n",
    "\n",
    "# Verify if NaN are replaced\n",
    "print(\"\\n\" + \"NaN values in validation data (1364 samples):\\n\", df_val_1364.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in validation data (2604 samples):\\n\", df_val_2064.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in validation data (3844 samples):\\n\", df_val_3844.isnull().sum())\n",
    "print(\"\\n\" + \"NaN values in validation data (27156 samples):\\n\", df_val_27156.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate column names in validation datasets\n",
    "print(df_val_1364.columns[df_val_1364.columns.duplicated()].unique()) \n",
    "print(df_val_2064.columns[df_val_2064.columns.duplicated()].unique()) \n",
    "print(df_val_3844.columns[df_val_3844.columns.duplicated()].unique()) \n",
    "print(df_val_27156.columns[df_val_27156.columns.duplicated()].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use df_training\n",
    "# Extract all column names from the training data as reference\n",
    "train_columns = df_training.columns.tolist()\n",
    "print(f\"Training data has {len(train_columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target column (CLASSIFIER) from feature columns\n",
    "# We align features only  the target column is handled separately\n",
    "target_col = 'CLASSIFIER'\n",
    "train_feature_cols = [col for col in train_columns if col != target_col]\n",
    "print(f\"Training has {len(train_feature_cols)} feature columns + '{target_col}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_train(df_val, train_feature_cols, target_col='CLASSIFIER'):\n",
    "    \"\"\"\n",
    "    Align a validation DataFrame so its features match training exactly.\n",
    "\n",
    "    Steps:\n",
    "      A) Add missing columns (in training but not in validation) filled with 0\n",
    "      B) Drop extra columns (in validation but not in training)\n",
    "      C) Reorder to match training column order\n",
    "      D) Re-attach the target column at the end\n",
    "    \"\"\"\n",
    "    # --- Step A: Find feature columns missing in validation ---\n",
    "    val_feature_cols = [c for c in df_val.columns if c != target_col]\n",
    "    missing_cols = set(train_feature_cols) - set(val_feature_cols)\n",
    "    print(f\"  Missing columns to add (filled with 0): {len(missing_cols)}\")\n",
    "\n",
    "    # --- Step B: Find extra columns in validation that training doesn't have ---\n",
    "    extra_cols = set(val_feature_cols) - set(train_feature_cols)\n",
    "    print(f\"  Extra columns to drop: {len(extra_cols)}\")\n",
    "\n",
    "    # --- Step C: Add missing columns with 0 ---\n",
    "    for col in missing_cols:\n",
    "        df_val[col] = 0\n",
    "\n",
    "    # --- Step D: Select only training features (in order) + target column ---\n",
    "    df_val = df_val[train_feature_cols + [target_col]]\n",
    "\n",
    "    return df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_1364\n",
    "print(\"Aligning df_val_1364:\")\n",
    "df_val_1364 = align_to_train(df_val_1364, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_1364.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_2064\n",
    "print(\"Aligning df_val_2064:\")\n",
    "df_val_2064 = align_to_train(df_val_2064, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_2064.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_3844\n",
    "print(\"Aligning df_val_3844:\")\n",
    "df_val_3844 = align_to_train(df_val_3844, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_3844.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_27156\n",
    "print(\"Aligning df_val_27156:\")\n",
    "df_val_27156 = align_to_train(df_val_27156, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_27156.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_2064\n",
    "print(\"Aligning df_val_2064:\")\n",
    "df_val_2064 = align_to_train(df_val_2064, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_2064.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_3844\n",
    "print(\"Aligning df_val_3844:\")\n",
    "df_val_3844 = align_to_train(df_val_3844, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_3844.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align df_val_27156\n",
    "print(\"Aligning df_val_27156:\")\n",
    "df_val_27156 = align_to_train(df_val_27156, train_feature_cols)\n",
    "print(f\"  Result shape: {df_val_27156.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder validation columns to exactly match df_training column order\n",
    "df_val_1364 = df_val_1364[df_training.columns]\n",
    "df_val_2064 = df_val_2064[df_training.columns]\n",
    "df_val_3844 = df_val_3844[df_training.columns]\n",
    "df_val_27156 = df_val_27156[df_training.columns]\n",
    "\n",
    "print(\" All validation sets reordered to match training column order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all aligned shapes and column order match training\n",
    "for name, df_val in [(\"df_val_1364\", df_val_1364),\n",
    "                      (\"df_val_2064\", df_val_2064),\n",
    "                      (\"df_val_3844\", df_val_3844),\n",
    "                      (\"df_val_27156\", df_val_27156)]:\n",
    "\n",
    "    assert df_val.shape[1] == df_training.shape[1], \\\n",
    "        f\"{name} has {df_val.shape[1]} cols, expected {df_training.shape[1]}\"\n",
    "\n",
    "    assert list(df_val.columns) == list(df_training.columns), \\\n",
    "        f\"{name} columns do not match training columns\"\n",
    "\n",
    "    print(f\" {name} aligned  shape: {df_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Extract validation features and labels #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Step 1: Separate features (X) and labels (y) for each validation set\n",
    "# Same pattern as: X_test_68 = df_testing_68.drop('CLASSIFIER', axis=1).values\n",
    "# \n",
    "\n",
    "X_val_1364  = df_val_1364.drop('CLASSIFIER', axis=1).values\n",
    "X_val_2064  = df_val_2064.drop('CLASSIFIER', axis=1).values\n",
    "X_val_3844  = df_val_3844.drop('CLASSIFIER', axis=1).values\n",
    "X_val_27156 = df_val_27156.drop('CLASSIFIER', axis=1).values\n",
    "\n",
    "y_val_1364  = df_val_1364['CLASSIFIER'].values\n",
    "y_val_2064  = df_val_2064['CLASSIFIER'].values\n",
    "y_val_3844  = df_val_3844['CLASSIFIER'].values\n",
    "y_val_27156 = df_val_27156['CLASSIFIER'].values\n",
    "\n",
    "print(f\"X_val_1364:  {X_val_1364.shape},  y_val_1364:  {y_val_1364.shape}\")\n",
    "print(f\"X_val_2064:  {X_val_2064.shape},  y_val_2064:  {y_val_2064.shape}\")\n",
    "print(f\"X_val_3844:  {X_val_3844.shape},  y_val_3844:  {y_val_3844.shape}\")\n",
    "print(f\"X_val_27156: {X_val_27156.shape}, y_val_27156: {y_val_27156.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Random Forest predictions on all validation sets #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Step 2: Get RF base model predictions (probability of class 1)\n",
    "# Each trained model variant (360, 1980, 3780, 5580) predicts on\n",
    "# each validation set  4 models  4 val sets = 16 prediction arrays\n",
    "# \n",
    "\n",
    "# RF predictions  model trained on 360 samples\n",
    "test_preds_RF_360_1364  = model_RF_360.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_RF_360_2064  = model_RF_360.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_RF_360_3844  = model_RF_360.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_RF_360_27156 = model_RF_360.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "# RF predictions  model trained on 1980 samples\n",
    "test_preds_RF_1980_1364  = model_RF_1980.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_RF_1980_2064  = model_RF_1980.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_RF_1980_3844  = model_RF_1980.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_RF_1980_27156 = model_RF_1980.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "# RF predictions  model trained on 3780 samples\n",
    "test_preds_RF_3780_1364  = model_RF_3780.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_RF_3780_2064  = model_RF_3780.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_RF_3780_3844  = model_RF_3780.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_RF_3780_27156 = model_RF_3780.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "# RF predictions  model trained on 5580 samples\n",
    "test_preds_RF_5580_1364  = model_RF_5580.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_RF_5580_2064  = model_RF_5580.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_RF_5580_3844  = model_RF_5580.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_RF_5580_27156 = model_RF_5580.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "print(\" RF predictions complete for all validation sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## LightGBM predictions on all validation sets #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Step 3: Get LightGBM base model predictions (probability of class 1)\n",
    "# Same approach: 4 models  4 val sets = 16 prediction arrays\n",
    "# \n",
    "\n",
    "# LGBM predictions  model trained on 360 samples\n",
    "test_preds_LGBM_360_1364  = model_LGBM_360.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_LGBM_360_2064  = model_LGBM_360.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_LGBM_360_3844  = model_LGBM_360.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_LGBM_360_27156 = model_LGBM_360.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "# LGBM predictions  model trained on 1980 samples\n",
    "test_preds_LGBM_1980_1364  = model_LGBM_1980.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_LGBM_1980_2064  = model_LGBM_1980.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_LGBM_1980_3844  = model_LGBM_1980.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_LGBM_1980_27156 = model_LGBM_1980.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "# LGBM predictions  model trained on 3780 samples\n",
    "test_preds_LGBM_3780_1364  = model_LGBM_3780.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_LGBM_3780_2064  = model_LGBM_3780.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_LGBM_3780_3844  = model_LGBM_3780.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_LGBM_3780_27156 = model_LGBM_3780.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "# LGBM predictions  model trained on 5580 samples\n",
    "test_preds_LGBM_5580_1364  = model_LGBM_5580.predict_proba(X_val_1364)[:, 1]\n",
    "test_preds_LGBM_5580_2064  = model_LGBM_5580.predict_proba(X_val_2064)[:, 1]\n",
    "test_preds_LGBM_5580_3844  = model_LGBM_5580.predict_proba(X_val_3844)[:, 1]\n",
    "test_preds_LGBM_5580_27156 = model_LGBM_5580.predict_proba(X_val_27156)[:, 1]\n",
    "\n",
    "print(\" LightGBM predictions complete for all validation sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## DNN predictions on all validation sets #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Step 4: Get DNN base model predictions\n",
    "# DNN requires: (a) convert to PyTorch tensor, (b) forward pass,\n",
    "# (c) apply softmax, (d) extract class-1 probability\n",
    "# \n",
    "\n",
    "# Convert validation features to PyTorch tensors on the correct device\n",
    "X_val_tensor_1364  = torch.tensor(X_val_1364,  dtype=torch.float32).to(device)\n",
    "X_val_tensor_2064  = torch.tensor(X_val_2064,  dtype=torch.float32).to(device)\n",
    "X_val_tensor_3844  = torch.tensor(X_val_3844,  dtype=torch.float32).to(device)\n",
    "X_val_tensor_27156 = torch.tensor(X_val_27156, dtype=torch.float32).to(device)\n",
    "\n",
    "# DNN predictions  using all 4 model variants (360, 1980, 3780, 5580)\n",
    "# Put each model in eval mode and disable gradient computation\n",
    "for model_name, model_obj in [(\"DNN_360\", model_DNN_360),\n",
    "                               (\"DNN_1980\", model_DNN_1980),\n",
    "                               (\"DNN_3780\", model_DNN_3780),\n",
    "                               (\"DNN_5580\", model_DNN_5580)]:\n",
    "    model_obj.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # model_DNN_360 predictions\n",
    "    test_preds_DNN_360_1364  = torch.softmax(model_DNN_360(X_val_tensor_1364),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_2064  = torch.softmax(model_DNN_360(X_val_tensor_2064),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_3844  = torch.softmax(model_DNN_360(X_val_tensor_3844),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_360_27156 = torch.softmax(model_DNN_360(X_val_tensor_27156), dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    # model_DNN_1980 predictions\n",
    "    test_preds_DNN_1980_1364  = torch.softmax(model_DNN_1980(X_val_tensor_1364),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_2064  = torch.softmax(model_DNN_1980(X_val_tensor_2064),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_3844  = torch.softmax(model_DNN_1980(X_val_tensor_3844),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_1980_27156 = torch.softmax(model_DNN_1980(X_val_tensor_27156), dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    # model_DNN_3780 predictions\n",
    "    test_preds_DNN_3780_1364  = torch.softmax(model_DNN_3780(X_val_tensor_1364),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_2064  = torch.softmax(model_DNN_3780(X_val_tensor_2064),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_3844  = torch.softmax(model_DNN_3780(X_val_tensor_3844),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_3780_27156 = torch.softmax(model_DNN_3780(X_val_tensor_27156), dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    # model_DNN_5580 predictions\n",
    "    test_preds_DNN_5580_1364  = torch.softmax(model_DNN_5580(X_val_tensor_1364),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_2064  = torch.softmax(model_DNN_5580(X_val_tensor_2064),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_3844  = torch.softmax(model_DNN_5580(X_val_tensor_3844),  dim=1)[:, 1].cpu().numpy()\n",
    "    test_preds_DNN_5580_27156 = torch.softmax(model_DNN_5580(X_val_tensor_27156), dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "print(\" DNN predictions complete for all validation sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Stack base model predictions into meta-features #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Step 5: Stack RF + LGBM + DNN predictions into 3-column matrices\n",
    "# Each row = one sample; each column = one base model's P(class=1)\n",
    "# These become the input features for the LR meta-learner\n",
    "# \n",
    "\n",
    "# Stacked predictions for val_1364\n",
    "test_preds_stack_360_1364  = np.column_stack([test_preds_RF_360_1364,  test_preds_LGBM_360_1364,  test_preds_DNN_360_1364])\n",
    "test_preds_stack_1980_1364 = np.column_stack([test_preds_RF_1980_1364, test_preds_LGBM_1980_1364, test_preds_DNN_1980_1364])\n",
    "test_preds_stack_3780_1364 = np.column_stack([test_preds_RF_3780_1364, test_preds_LGBM_3780_1364, test_preds_DNN_3780_1364])\n",
    "test_preds_stack_5580_1364 = np.column_stack([test_preds_RF_5580_1364, test_preds_LGBM_5580_1364, test_preds_DNN_5580_1364])\n",
    "\n",
    "# Stacked predictions for val_2064\n",
    "test_preds_stack_360_2064  = np.column_stack([test_preds_RF_360_2064,  test_preds_LGBM_360_2064,  test_preds_DNN_360_2064])\n",
    "test_preds_stack_1980_2064 = np.column_stack([test_preds_RF_1980_2064, test_preds_LGBM_1980_2064, test_preds_DNN_1980_2064])\n",
    "test_preds_stack_3780_2064 = np.column_stack([test_preds_RF_3780_2064, test_preds_LGBM_3780_2064, test_preds_DNN_3780_2064])\n",
    "test_preds_stack_5580_2064 = np.column_stack([test_preds_RF_5580_2064, test_preds_LGBM_5580_2064, test_preds_DNN_5580_2064])\n",
    "\n",
    "# Stacked predictions for val_3844\n",
    "test_preds_stack_360_3844  = np.column_stack([test_preds_RF_360_3844,  test_preds_LGBM_360_3844,  test_preds_DNN_360_3844])\n",
    "test_preds_stack_1980_3844 = np.column_stack([test_preds_RF_1980_3844, test_preds_LGBM_1980_3844, test_preds_DNN_1980_3844])\n",
    "test_preds_stack_3780_3844 = np.column_stack([test_preds_RF_3780_3844, test_preds_LGBM_3780_3844, test_preds_DNN_3780_3844])\n",
    "test_preds_stack_5580_3844 = np.column_stack([test_preds_RF_5580_3844, test_preds_LGBM_5580_3844, test_preds_DNN_5580_3844])\n",
    "\n",
    "# Stacked predictions for val_27156\n",
    "test_preds_stack_360_27156  = np.column_stack([test_preds_RF_360_27156,  test_preds_LGBM_360_27156,  test_preds_DNN_360_27156])\n",
    "test_preds_stack_1980_27156 = np.column_stack([test_preds_RF_1980_27156, test_preds_LGBM_1980_27156, test_preds_DNN_1980_27156])\n",
    "test_preds_stack_3780_27156 = np.column_stack([test_preds_RF_3780_27156, test_preds_LGBM_3780_27156, test_preds_DNN_3780_27156])\n",
    "test_preds_stack_5580_27156 = np.column_stack([test_preds_RF_5580_27156, test_preds_LGBM_5580_27156, test_preds_DNN_5580_27156])\n",
    "\n",
    "print(\" All base model predictions stacked into meta-features\")\n",
    "print(f\"   Example shape: {test_preds_stack_360_1364.shape}\")  # Should be (n_samples, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Final ensemble predictions from meta-learner #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Step 6: Feed stacked predictions into the LR meta-learner\n",
    "# Each meta-model variant (360, 1980, 3780, 5580) predicts on each\n",
    "# validation set. Output: probability of class 1  binary prediction\n",
    "# \n",
    "\n",
    "# --- val_1364 ---\n",
    "final_probs_LR_360_1364  = meta_model_LR_360.predict_proba(test_preds_stack_360_1364)[:, 1]\n",
    "final_probs_LR_1980_1364 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_1364)[:, 1]\n",
    "final_probs_LR_3780_1364 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_1364)[:, 1]\n",
    "final_probs_LR_5580_1364 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_1364)[:, 1]\n",
    "\n",
    "final_preds_LR_360_1364  = (final_probs_LR_360_1364  >= 0.5).astype(int)\n",
    "final_preds_LR_1980_1364 = (final_probs_LR_1980_1364 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_1364 = (final_probs_LR_3780_1364 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_1364 = (final_probs_LR_5580_1364 >= 0.5).astype(int)\n",
    "\n",
    "# --- val_2064 ---\n",
    "final_probs_LR_360_2064  = meta_model_LR_360.predict_proba(test_preds_stack_360_2064)[:, 1]\n",
    "final_probs_LR_1980_2064 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_2064)[:, 1]\n",
    "final_probs_LR_3780_2064 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_2064)[:, 1]\n",
    "final_probs_LR_5580_2064 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_2064)[:, 1]\n",
    "\n",
    "final_preds_LR_360_2064  = (final_probs_LR_360_2064  >= 0.5).astype(int)\n",
    "final_preds_LR_1980_2064 = (final_probs_LR_1980_2064 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_2064 = (final_probs_LR_3780_2064 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_2064 = (final_probs_LR_5580_2064 >= 0.5).astype(int)\n",
    "\n",
    "# --- val_3844 ---\n",
    "final_probs_LR_360_3844  = meta_model_LR_360.predict_proba(test_preds_stack_360_3844)[:, 1]\n",
    "final_probs_LR_1980_3844 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_3844)[:, 1]\n",
    "final_probs_LR_3780_3844 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_3844)[:, 1]\n",
    "final_probs_LR_5580_3844 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_3844)[:, 1]\n",
    "\n",
    "final_preds_LR_360_3844  = (final_probs_LR_360_3844  >= 0.5).astype(int)\n",
    "final_preds_LR_1980_3844 = (final_probs_LR_1980_3844 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_3844 = (final_probs_LR_3780_3844 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_3844 = (final_probs_LR_5580_3844 >= 0.5).astype(int)\n",
    "\n",
    "# --- val_27156 ---\n",
    "final_probs_LR_360_27156  = meta_model_LR_360.predict_proba(test_preds_stack_360_27156)[:, 1]\n",
    "final_probs_LR_1980_27156 = meta_model_LR_1980.predict_proba(test_preds_stack_1980_27156)[:, 1]\n",
    "final_probs_LR_3780_27156 = meta_model_LR_3780.predict_proba(test_preds_stack_3780_27156)[:, 1]\n",
    "final_probs_LR_5580_27156 = meta_model_LR_5580.predict_proba(test_preds_stack_5580_27156)[:, 1]\n",
    "\n",
    "final_preds_LR_360_27156  = (final_probs_LR_360_27156  >= 0.5).astype(int)\n",
    "final_preds_LR_1980_27156 = (final_probs_LR_1980_27156 >= 0.5).astype(int)\n",
    "final_preds_LR_3780_27156 = (final_probs_LR_3780_27156 >= 0.5).astype(int)\n",
    "final_preds_LR_5580_27156 = (final_probs_LR_5580_27156 >= 0.5).astype(int)\n",
    "\n",
    "print(\" All ensemble predictions complete for validation sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- External validation: val_1364 ---\n",
    "metrics_val_360_1364  = evaluate_meta_model_with_ci(y_val_1364, final_probs_LR_360_1364,  threshold=0.5)\n",
    "metrics_val_1980_1364 = evaluate_meta_model_with_ci(y_val_1364, final_probs_LR_1980_1364, threshold=0.5)\n",
    "metrics_val_3780_1364 = evaluate_meta_model_with_ci(y_val_1364, final_probs_LR_3780_1364, threshold=0.5)\n",
    "metrics_val_5580_1364 = evaluate_meta_model_with_ci(y_val_1364, final_probs_LR_5580_1364, threshold=0.5)\n",
    "\n",
    "# --- External validation: val_2064 ---\n",
    "metrics_val_360_2064  = evaluate_meta_model_with_ci(y_val_2064, final_probs_LR_360_2064,  threshold=0.5)\n",
    "metrics_val_1980_2064 = evaluate_meta_model_with_ci(y_val_2064, final_probs_LR_1980_2064, threshold=0.5)\n",
    "metrics_val_3780_2064 = evaluate_meta_model_with_ci(y_val_2064, final_probs_LR_3780_2064, threshold=0.5)\n",
    "metrics_val_5580_2064 = evaluate_meta_model_with_ci(y_val_2064, final_probs_LR_5580_2064, threshold=0.5)\n",
    "\n",
    "# --- External validation: val_3844 ---\n",
    "metrics_val_360_3844  = evaluate_meta_model_with_ci(y_val_3844, final_probs_LR_360_3844,  threshold=0.5)\n",
    "metrics_val_1980_3844 = evaluate_meta_model_with_ci(y_val_3844, final_probs_LR_1980_3844, threshold=0.5)\n",
    "metrics_val_3780_3844 = evaluate_meta_model_with_ci(y_val_3844, final_probs_LR_3780_3844, threshold=0.5)\n",
    "metrics_val_5580_3844 = evaluate_meta_model_with_ci(y_val_3844, final_probs_LR_5580_3844, threshold=0.5)\n",
    "\n",
    "# --- External validation: val_27156 ---\n",
    "metrics_val_360_27156  = evaluate_meta_model_with_ci(y_val_27156, final_probs_LR_360_27156,  threshold=0.5)\n",
    "metrics_val_1980_27156 = evaluate_meta_model_with_ci(y_val_27156, final_probs_LR_1980_27156, threshold=0.5)\n",
    "metrics_val_3780_27156 = evaluate_meta_model_with_ci(y_val_27156, final_probs_LR_3780_27156, threshold=0.5)\n",
    "metrics_val_5580_27156 = evaluate_meta_model_with_ci(y_val_27156, final_probs_LR_5580_27156, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7853785,
     "sourceId": 12450259,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
